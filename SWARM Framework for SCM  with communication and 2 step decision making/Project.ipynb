{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53840fd1-3024-4dd1-856a-9db77dc1b7f1",
   "metadata": {},
   "source": [
    "## SWARM Framework for Supply Chain Management with communication and 2 step decision making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc96297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable demand for t=0: 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from typing import List\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# CHANGED: Possibly import new config or reuse existing\n",
    "from config import env_configs\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "396d8d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant_demand demand for t=0: 4\n",
      "variable_demand demand for t=0: 3\n",
      "larger_demand demand for t=0: 7\n",
      "seasonal_demand demand for t=0: 4\n",
      "normal_demand demand for t=0: 1\n",
      "increasing_demand demand for t=0: 5\n",
      "cyclical_demand demand for t=0: 5\n",
      "demand_shock demand for t=0: 5\n",
      "stochastic_demand demand for t=0: 0\n"
     ]
    }
   ],
   "source": [
    "for name, config in env_configs.items():\n",
    "    # Evaluate demand function at a specific time, say t=0.\n",
    "    demand_value = config['demand_fn'](0)\n",
    "    print(f\"{name} demand for t=0: {demand_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdfb02c-ee95-4ea3-a70d-e64562672581",
   "metadata": {},
   "source": [
    "## Initializing the environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db702607",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85d1af5d-1f32-4fc4-bba1-b4514fab0a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the communication with the API \n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {os.getenv('OPENAI_API_KEY')}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "456a5fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_stages': 4, 'num_periods': 12, 'init_inventories': [12, 12, 12, 12], 'lead_times': [2, 2, 2, 2], 'demand_fn': <function <lambda> at 0x0000021EF952D8A0>, 'prod_capacities': [20, 20, 20, 20], 'sale_prices': [5, 5, 5, 5], 'order_costs': [5, 5, 5, 5], 'backlog_costs': [1, 1, 1, 1], 'holding_costs': [1, 1, 1, 1], 'stage_names': ['retailer', 'wholesaler', 'distributor', 'manufacturer'], 'comm_size': 4}\n",
      "<DecentralizedInventoryEnvWithComm instance>\n"
     ]
    }
   ],
   "source": [
    "# 1) Build environment\n",
    "from env import  DecentralizedInventoryEnvWithComm\n",
    "from config import env_configs\n",
    "env_config_name = \"seasonal_demand\"\n",
    "env_config = env_configs[env_config_name]\n",
    "print(env_config)  \n",
    "\n",
    "\n",
    "im_env =  DecentralizedInventoryEnvWithComm(**env_config)\n",
    "im_env.config = env_config\n",
    "print(im_env)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c0e869-9146-4fc4-93c8-effdf0a1f6f9",
   "metadata": {},
   "source": [
    "## Function definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03573f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_observation(obs, stage_index, max_lead_time, num_stages, comm_size):\n",
    "    \"\"\"\n",
    "    Converting a single row from the environment's observation matrix into a user-friendly\n",
    "    text description for that stage.\n",
    "\n",
    "    The observation for each stage is structured as follows:\n",
    "      - Base state: first 9 + 2 * max_lead_time elements, where:\n",
    "          [0]   : production capacity\n",
    "          [1]   : sale price\n",
    "          [2]   : order cost\n",
    "          [3]   : backlog cost\n",
    "          [4]   : holding cost\n",
    "          [5]   : stage-specific lead time (but base state is allocated with max_lead_time)\n",
    "          [6]   : inventory\n",
    "          [7]   : backlog\n",
    "          [8]   : upstream backlog (backlog of the next stage; for the last stage this might be unused)\n",
    "          [9 : 9+max_lead_time]       : sales (using fixed max lead time slicing)\n",
    "          [9+max_lead_time : 9+2*max_lead_time] : deliveries\n",
    "      - Communication messages: the remaining elements (a flattened vector of shape (num_stages * comm_size,))\n",
    "\n",
    "    Parameters:\n",
    "      obs (np.array): The observation, which could be a single row or a 2D array (multi-stage).\n",
    "      stage_index (int): The stage index to parse (only used if obs is multi-stage).\n",
    "      max_lead_time (int): The maximum lead time used in the environment.\n",
    "      num_stages (int): The total number of stages.\n",
    "      comm_size (int): The size of the communication vector for each stage.\n",
    "      \n",
    "    Returns:\n",
    "      str: A string summarizing the parsed observation for the given stage.\n",
    "    \"\"\"\n",
    "    # Handle both single-stage (1D) and multi-stage (2D) observations.\n",
    "    if obs.ndim == 1:\n",
    "        row = obs\n",
    "    else:\n",
    "        row = obs[stage_index]\n",
    "    \n",
    "    # Computing the length of the base state from max lead time.\n",
    "    base_dim = 9 + 2 * max_lead_time\n",
    "    base = row[:base_dim]\n",
    "    communications = row[base_dim:]\n",
    "    \n",
    "    # Extracting base state values.\n",
    "    prod_capacity = base[0]\n",
    "    sale_price = base[1]\n",
    "    order_cost = base[2]\n",
    "    backlog_cost = base[3]\n",
    "    holding_cost = base[4]\n",
    "    lead_time = int(base[5])\n",
    "    inventory = base[6]\n",
    "    backlog = base[7]\n",
    "    next_stage_backlog = base[8]\n",
    "    \n",
    "    # Dynamically extracting only the relevant number of past sales & deliveries based on lead_time\n",
    "    if lead_time > 0:\n",
    "        sales = base[-2 * max_lead_time : -max_lead_time][-lead_time:].tolist()\n",
    "        deliveries = base[-max_lead_time:][-lead_time:].tolist()\n",
    "    else:\n",
    "        sales = []\n",
    "        deliveries = []\n",
    "    \n",
    "    # The communications vector is a flattened array of length num_stages * comm_size.\n",
    "    communications_list = communications.tolist()\n",
    "    \n",
    "    info_str = (\n",
    "        f\"Production Capacity = {prod_capacity}, Sale Price = {sale_price}, Order Cost = {order_cost}, \"\n",
    "        f\"Backlog Cost = {backlog_cost}, Holding Cost = {holding_cost}, Stage Lead Time = {lead_time}, \"\n",
    "        f\"Inventory = {inventory}, Current Backlog (you owing to the downstream) = {backlog}, \"\n",
    "        f\"Upstream Backlog (your upstream owing to you) = {next_stage_backlog}, \"\n",
    "        f\"Previous Sales (in the recent period(s), from old to new)={sales}, \"\n",
    "        f\"Arriving Deliveries (in this and the next period(s), from near to far) = {deliveries}\"\n",
    "    )\n",
    "    \n",
    "    return info_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f3346ca-c92f-4724-a35b-4662a7e55e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_demand_description(env_config_name):\n",
    "    \"\"\"\n",
    "    Specifying a description for the demand scenario based on the environment configuration name.\n",
    "    \"\"\"\n",
    "    demand_description = {\n",
    "        \"constant_demand\": \"The expected demand at the retailer(stage 1) is a constant value of 4 units for all 12 periods.\",\n",
    "        \"variable_demand\": \"The expected demand at the retailer (stage 1) is a discrete uniform distribution U{0, 4} for all 12 periods.\",\n",
    "        \"larger_demand\": \"The expected demand at the retailer (stage 1) is a discrete uniform distribution U{0, 9} for all 12 periods.\",\n",
    "        \"seasonal_demand\": \"For the first four periods, demand at the retailer(stage 1) follows a discrete uniform distribution over {0, 1, 2, 3, 4}, and for the following eight periods, it follows a discrete uniform distribution over {5, 6, 7, 8}.\",\n",
    "        \"normal_demand\": \"The expected demand at the retailer (stage 1) is a normal distribution N(4, 2^2), \" \\\n",
    "            \"truncated at 0, for all 12 periods.\",\n",
    "        \"increasing_demand\": \"The expected demand at the retailer (stage 1) is a linearly increasing demand by starting with an initial value 5 and growing by 1 unit every period\",\n",
    "        \"cyclical_demand\": \" The expected demand at the retailer (stage 1) is computed as a seasonal sine wave—with a 12-round period, a 5-unit amplitude, and a 5-unit upward shift—whose value is rounded to yield an integer.\",\n",
    "        \"demand_shock\": \"The expected demand at the retailer (stage 1) is normally 5, but it jumps by 8 units to 13 during periods 8 through 10, capturing a temporary demand shock. \",\n",
    "        \"stochastic_demand\": \"The expected demand at the retailer (stage 1) is an Integer-Valued Autoregressive INAR(1) process with a thinning probability of 0.5, meaning 50% of the previous period's demand carries over. New demand is added as Poisson arrivals with a mean of 2, ensuring the overall demand remains an integer count.\",\n",
    "    }\n",
    "    return demand_description.get(env_config_name, \"Unknown demand configuration.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45f7d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_order_and_comm(response_str: str, comm_size: int):\n",
    "    \n",
    "    import logging\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    # 1) Parse order quantity strictly, in case of inadequate response from the LLM. Using regex pattern.\n",
    "    order_pattern = r\"\\[Order\\s*quantity:\\s*(\\d+)\\]\"\n",
    "    order_match = re.search(order_pattern, response_str, re.IGNORECASE)\n",
    "    if order_match:\n",
    "        order_qty = int(order_match.group(1))\n",
    "    else:\n",
    "        logger.warning(\"Order quantity not found. Defaulting to 0.\")\n",
    "        order_qty = 0\n",
    "\n",
    "   #  2) Parse the communication vector\n",
    "    comm_pattern = r\"\\[Comm\\s*vector:\\s*([^\\]]+)\\]\"\n",
    "    comm_match = re.search(comm_pattern, response_str, re.IGNORECASE)\n",
    "    if comm_match:\n",
    "        values_str = comm_match.group(1)\n",
    "        try:\n",
    "           # Parsing the comma-separated values.\n",
    "            values = [float(x.strip()) for x in values_str.split(\",\")]\n",
    "        except ValueError:\n",
    "            logger.warning(\"Error parsing communication vector. Defaulting to zeros.\")\n",
    "            values = []\n",
    "\n",
    "        # Ensure the communication vector has exactly comm_size elements.\n",
    "        if len(values) < comm_size:\n",
    "            logger.warning(f\"Communication vector has fewer than expected {comm_size} values; padding with zeros.\")\n",
    "            values += [0.0] * (comm_size - len(values))\n",
    "        elif len(values) > comm_size:\n",
    "            logger.warning(f\"Communication vector has more than expected {comm_size} values; truncating.\")\n",
    "            values = values[:comm_size]\n",
    "\n",
    "        comm_array = np.array(values, dtype=np.float32)\n",
    "    else:\n",
    "        logger.warning(\"Communication vector not found. Defaulting to zeros.\")\n",
    "        comm_array = np.zeros(comm_size, dtype=np.float32)\n",
    "\n",
    "    return order_qty, comm_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcd7a6b-28dc-4a78-a0aa-f8152b9ccf5a",
   "metadata": {},
   "source": [
    "## Agent creation and simulation definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de98e3b2-ec57-46ef-b9ad-81cb60f84c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "from swarm import Agent, Swarm\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Definition of a dataclass for agent actions\n",
    "@dataclass\n",
    "class Action:\n",
    "    order_quantity: float\n",
    "    comm_vector: np.ndarray\n",
    "\n",
    "def create_agents(stage_names: List[str]) -> List[Agent]:\n",
    "    \"\"\"\n",
    "    Creating agents for each stage with instructions tailored to their role.\n",
    "    \"\"\"\n",
    "    agents = []\n",
    "    num_stages = len(stage_names)\n",
    "    demand_description = get_demand_description(env_config_name)  # Assume global definition\n",
    "\n",
    "    for stage, stage_name in enumerate(stage_names):\n",
    "        instructions = (\n",
    "            f\"You represent stage {stage + 1} ('{stage_name}') in a {num_stages}-stage supply chain.\\n\\n\"\n",
    "            \"You are an expert in inventory management and optimization\"\n",
    "            \"Your Objective:\\n\"\n",
    "            \"Your goal is to minimize the total cost (order, holding, backlog) by making ordering decisions and effectively communicating with neighboring stages.\\n\"\n",
    "            f\"{demand_description}\\n\\n\"\n",
    "            \"Decision Process per Period:\\n\"\n",
    "            \"1. Initial Decision: Provide your initial order quantity and initial communication vector before receiving neighbor inputs.\\n\"\n",
    "            \"2. Updated Decision: After receiving upstream and downstream neighbor communications, revise and provide your final order quantity and final communication vector.\\n\\n\"\n",
    "            \"Your communication vector has four dimensions:\\n\"\n",
    "            \"- v1: Current inventory level\\n\"\n",
    "            \"- v2: Order quantity placed this round\\n\"\n",
    "            \"- v3: Urgency level or risk indicator\\n\\n\"\n",
    "            \"- v4: Current lead time\\n\\n\"\n",
    "        )\n",
    "        agent = Agent(\n",
    "            name=f\"{stage_name.capitalize()}_Agent\",\n",
    "            instructions=instructions,\n",
    "            model=\"o3-mini\"\n",
    "        )\n",
    "        agents.append(agent)\n",
    "    \n",
    "    return agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab6bf76c-4c24-4b29-9ff5-29770f7bc51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encapsulating API call within a class method, ensuring that the setup is handled in one place\n",
    "class Swarm:\n",
    "    def __init__(self):\n",
    "        # existing initialization\n",
    "        pass\n",
    "\n",
    "    def run(self, agent: Agent, messages: List[Dict[str, str]], temperature: float = 0.7) -> Any:\n",
    "        data = {\n",
    "            \"model\": os.getenv(\"OPENAI_MODEL\", \"o3-mini\"),\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": temperature,\n",
    "            \"reasoning effort\": high\n",
    "        }\n",
    "        # Now make your API call using requests or your preferred HTTP client\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", json=data, headers=your_headers)\n",
    "        # Process and return the response as needed\n",
    "        return response.json()  # or your wrapped response object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a035a902-81a6-40c1-a71a-d20567b0d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from swarm import Swarm\n",
    "\n",
    "\n",
    "# Configure the main logger\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# Reducing verbosity for external modules\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def run_simulation_swarm(env_config_name: str, env: Any, stage_agents: List[Agent]) -> float:\n",
    "    obs, _ = env.reset()\n",
    "    \n",
    "    if env_config_name == 'stochastic_demand':\n",
    "        logger.info(\"Generating a new stochastic demand series...\")\n",
    "        env.config[\"demand_fn\"].generate_new_series()\n",
    "\n",
    "    client = Swarm()\n",
    "    done = False\n",
    "    total_reward = 0.0\n",
    "    period = 0\n",
    "\n",
    "    logger.info(f\"Simulation started: {env_config_name}\\n{'=' * 80}\")\n",
    "\n",
    "    while not done and period < env.num_periods:\n",
    "        logger.info(f\"--- PERIOD {period + 1} ---\")\n",
    "\n",
    "        # Preliminary Decisions (sequential)\n",
    "        preliminary_actions: List[Action] = []\n",
    "        for stage_idx in range(env.num_stages):\n",
    "            stage_name = env.stage_names[stage_idx].capitalize()\n",
    "            local_obs = obs[f\"stage_{stage_idx}\"]\n",
    "\n",
    "            input_message = (\n",
    "                f\"--- {stage_name} (Stage {stage_idx + 1}) ---\\n\"\n",
    "                f\"Current period: {period + 1}\\n\"\n",
    "                f\"Overview: {parse_observation(local_obs, stage_idx, env.max_lead_time, env.num_stages, env.comm_size)}\\n\\n\"\n",
    "                \"Decision Task: Make an initial order decision.\\n\"\n",
    "                \"Format: [Order quantity: X] [Comm vector: v1, v2, v3, v4]\\n\"\n",
    "            )\n",
    "\n",
    "            response = client.run(\n",
    "                agent=stage_agents[stage_idx],\n",
    "                messages=[{\"role\": \"user\", \"content\": input_message}]\n",
    "            )\n",
    "\n",
    "            # Log a response summary instead of the full-text\n",
    "            assistant_message = response.messages[-1][\"content\"]\n",
    "            try:\n",
    "                order_qty, comm_vec = parse_order_and_comm(assistant_message, env.comm_size)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Parsing failed for {stage_name}, defaulting to zero. Error: {e}\")\n",
    "                order_qty, comm_vec = 0, np.zeros(env.comm_size, dtype=np.float32)\n",
    "            \n",
    "            preliminary_actions.append(Action(order_quantity=order_qty, comm_vector=comm_vec))\n",
    "            logger.info(f\"{stage_name} preliminary decision: [Order quantity: {order_qty}] [Comm vector: {comm_vec.tolist()}]\")\n",
    "\n",
    "        # Build communication messages after preliminary decisions\n",
    "        downstream_messages = [None] * env.num_stages\n",
    "        upstream_messages = [None] * env.num_stages\n",
    "        for stage_idx in range(env.num_stages):\n",
    "            stage_name = env.stage_names[stage_idx].capitalize()\n",
    "            order_qty = preliminary_actions[stage_idx].order_quantity\n",
    "            comm_vec = preliminary_actions[stage_idx].comm_vector\n",
    "\n",
    "            if stage_idx < env.num_stages - 1:\n",
    "                downstream_messages[stage_idx + 1] = f\"[From {stage_name}]: Ordered {order_qty} units. Comm vector: {comm_vec.tolist()}\"\n",
    "            if stage_idx > 0:\n",
    "                upstream_messages[stage_idx - 1] = f\"[Notification from {stage_name}]: Order {order_qty} units planned.\"\n",
    "\n",
    "        # Updated Decisions (sequential)\n",
    "        final_actions: List[Action] = []\n",
    "        for stage_idx in range(env.num_stages):\n",
    "            stage_name = env.stage_names[stage_idx].capitalize()\n",
    "            local_obs = obs[f\"stage_{stage_idx}\"]\n",
    "\n",
    "            downstream_msg = downstream_messages[stage_idx]\n",
    "            upstream_msg = upstream_messages[stage_idx]\n",
    "\n",
    "            input_message = (\n",
    "                f\"--- {stage_name} (Stage {stage_idx + 1}) UPDATE ---\\n\"\n",
    "                f\"Current period: {period + 1}\\n\"\n",
    "                f\"Local state: {parse_observation(local_obs, stage_idx, env.max_lead_time, env.num_stages, env.comm_size)}\\n\\n\"\n",
    "            )\n",
    "            if downstream_msg:\n",
    "                input_message += f\"Downstream message: {downstream_msg}\\n\"\n",
    "            if upstream_msg:\n",
    "                input_message += f\"Upstream message: {upstream_msg}\\n\"\n",
    "            input_message += (\n",
    "                \"\\nUpdated Decision Task: Adjust your order decision.\\n\"\n",
    "                \"Format: [Order quantity: X] [Comm vector: v1, v2, v3, v4]\\n\"\n",
    "            )\n",
    "\n",
    "            response = client.run(\n",
    "                agent=stage_agents[stage_idx],\n",
    "                messages=[{\"role\": \"user\", \"content\": input_message}]\n",
    "            )\n",
    "\n",
    "            assistant_message = response.messages[-1][\"content\"]\n",
    "            try:\n",
    "                order_qty, comm_vec = parse_order_and_comm(assistant_message, env.comm_size)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Parsing failed for {stage_name} on update, defaulting to zero. Error: {e}\")\n",
    "                order_qty, comm_vec = 0, np.zeros(env.comm_size, dtype=np.float32)\n",
    "            \n",
    "            final_actions.append(Action(order_quantity=order_qty, comm_vector=comm_vec))\n",
    "            logger.info(f\"{stage_name} updated decision: [Order quantity: {order_qty}] [Comm vector: {comm_vec.tolist()}]\")\n",
    "\n",
    "        # Log final actions and environment update\n",
    "        action_dict: Dict[str, Tuple[float, np.ndarray]] = {\n",
    "            f\"stage_{m}\": (action.order_quantity, action.comm_vector)\n",
    "            for m, action in enumerate(final_actions)\n",
    "        }\n",
    "        next_obs, reward, terminations, truncations, info = env.step(action_dict)\n",
    "        step_reward = sum(reward.values())\n",
    "        total_reward += step_reward\n",
    "        done = terminations[\"__all__\"]\n",
    "\n",
    "        logger.info(f\"Reward: {reward}, Total Reward: {total_reward}\")\n",
    "        logger.info(\"=\" * 80)\n",
    "        obs = next_obs\n",
    "        period += 1\n",
    "\n",
    "    logger.info(\"Simulation finished.\")\n",
    "    return total_reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e58dce-59e8-442b-b2fc-f8bd3562b2ab",
   "metadata": {},
   "source": [
    "## Running the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bd0f90d-7fd8-47bf-b73c-f92498a7d591",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324a9c50b887478991c6549bf65faf2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Simulation started: seasonal_demand\n",
      "================================================================================\n",
      "INFO:__main__:--- PERIOD 1 ---\n",
      "INFO:__main__:Retailer preliminary decision: [Order quantity: 0] [Comm vector: [12.0, 0.0, 0.0, 2.0]]\n",
      "INFO:__main__:Wholesaler preliminary decision: [Order quantity: 0] [Comm vector: [12.0, 0.0, 0.0, 2.0]]\n",
      "INFO:__main__:Distributor preliminary decision: [Order quantity: 4] [Comm vector: [12.0, 4.0, 0.0, 2.0]]\n",
      "INFO:__main__:Manufacturer preliminary decision: [Order quantity: 8] [Comm vector: [12.0, 8.0, 1.0, 2.0]]\n",
      "INFO:__main__:Retailer updated decision: [Order quantity: 0] [Comm vector: [12.0, 0.0, 0.0, 2.0]]\n",
      "INFO:__main__:Wholesaler updated decision: [Order quantity: 0] [Comm vector: [12.0, 0.0, 0.0, 2.0]]\n",
      "INFO:__main__:Distributor updated decision: [Order quantity: 0] [Comm vector: [12.0, 0.0, 0.0, 2.0]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m stage_agents \u001b[38;5;241m=\u001b[39m create_agents(env_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage_names\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#  Run the simulation \u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m total_reward \u001b[38;5;241m=\u001b[39m run_simulation_swarm(env_config_name, im_env, stage_agents)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Collect the reward from this iteration.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m all_rewards\u001b[38;5;241m.\u001b[39mappend(total_reward)\n",
      "Cell \u001b[1;32mIn[11], line 99\u001b[0m, in \u001b[0;36mrun_simulation_swarm\u001b[1;34m(env_config_name, env, stage_agents)\u001b[0m\n\u001b[0;32m     93\u001b[0m     input_message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpstream message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mupstream_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m input_message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mUpdated Decision Task: Adjust your order decision.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFormat: [Order quantity: X] [Comm vector: v1, v2, v3, v4]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m )\n\u001b[1;32m---> 99\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m    100\u001b[0m     agent\u001b[38;5;241m=\u001b[39mstage_agents[stage_idx],\n\u001b[0;32m    101\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_message}]\n\u001b[0;32m    102\u001b[0m )\n\u001b[0;32m    104\u001b[0m assistant_message \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmessages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\swarm\\core.py:260\u001b[0m, in \u001b[0;36mSwarm.run\u001b[1;34m(self, agent, messages, context_variables, model_override, stream, debug, max_turns, execute_tools)\u001b[0m\n\u001b[0;32m    255\u001b[0m init_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(messages)\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(history) \u001b[38;5;241m-\u001b[39m init_len \u001b[38;5;241m<\u001b[39m max_turns \u001b[38;5;129;01mand\u001b[39;00m active_agent:\n\u001b[0;32m    258\u001b[0m \n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# get completion with current history, agent\u001b[39;00m\n\u001b[1;32m--> 260\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_chat_completion(\n\u001b[0;32m    261\u001b[0m         agent\u001b[38;5;241m=\u001b[39mactive_agent,\n\u001b[0;32m    262\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    263\u001b[0m         context_variables\u001b[38;5;241m=\u001b[39mcontext_variables,\n\u001b[0;32m    264\u001b[0m         model_override\u001b[38;5;241m=\u001b[39mmodel_override,\n\u001b[0;32m    265\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    266\u001b[0m         debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m    267\u001b[0m     )\n\u001b[0;32m    268\u001b[0m     message \u001b[38;5;241m=\u001b[39m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\n\u001b[0;32m    269\u001b[0m     debug_print(debug, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived completion:\u001b[39m\u001b[38;5;124m\"\u001b[39m, message)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\swarm\\core.py:69\u001b[0m, in \u001b[0;36mSwarm.get_chat_completion\u001b[1;34m(self, agent, history, context_variables, model_override, stream, debug)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tools:\n\u001b[0;32m     67\u001b[0m     create_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mparallel_tool_calls\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcreate_params)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:914\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    911\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    912\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    913\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    915\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    916\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    917\u001b[0m             {\n\u001b[0;32m    918\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    919\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    920\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[0;32m    921\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    922\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    923\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    924\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    925\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    926\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m    927\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    928\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    929\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[0;32m    930\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    931\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    932\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[0;32m    933\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    934\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[0;32m    935\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    936\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    937\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m    938\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    939\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m    940\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    941\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m    942\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    943\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    944\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    945\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    946\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    947\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    948\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[0;32m    949\u001b[0m             },\n\u001b[0;32m    950\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    951\u001b[0m         ),\n\u001b[0;32m    952\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    953\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    954\u001b[0m         ),\n\u001b[0;32m    955\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    956\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    957\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    958\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\openai\\_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1241\u001b[0m     )\n\u001b[1;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\openai\\_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    920\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    921\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    922\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    923\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    924\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m    925\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\openai\\_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m    952\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 955\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    956\u001b[0m         request,\n\u001b[0;32m    957\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    959\u001b[0m     )\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    961\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[0;32m    910\u001b[0m )\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m    915\u001b[0m     request,\n\u001b[0;32m    916\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    917\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    918\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    919\u001b[0m )\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m    943\u001b[0m         request,\n\u001b[0;32m    944\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    945\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    946\u001b[0m     )\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\httpx\\_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1012\u001b[0m     )\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\httpx\\_transports\\default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    231\u001b[0m )\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    242\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_closed(status)\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;66;03m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;66;03m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;66;03m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# up as HTTP/1.1.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool_lock:\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;66;03m# Maintain our position in the request queue, but reset the\u001b[39;00m\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;66;03m# status so that the request becomes queued again.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\httpcore\\_sync\\http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\httpcore\\_sync\\http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    105\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    106\u001b[0m     (\n\u001b[0;32m    107\u001b[0m         http_version,\n\u001b[0;32m    108\u001b[0m         status,\n\u001b[0;32m    109\u001b[0m         reason_phrase,\n\u001b[0;32m    110\u001b[0m         headers,\n\u001b[1;32m--> 111\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    112\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    113\u001b[0m         http_version,\n\u001b[0;32m    114\u001b[0m         status,\n\u001b[0;32m    115\u001b[0m         reason_phrase,\n\u001b[0;32m    116\u001b[0m         headers,\n\u001b[0;32m    117\u001b[0m     )\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    120\u001b[0m     status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[0;32m    121\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m     },\n\u001b[0;32m    128\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\httpcore\\_sync\\http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    173\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 176\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\httpcore\\_sync\\http11.py:212\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    209\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 212\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    214\u001b[0m     )\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\ssl.py:1295\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1292\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1293\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1294\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\ssl.py:1168\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "num_iterations = 5  # or however many iterations you want\n",
    "all_rewards = []\n",
    "\n",
    "for i in tqdm(range(num_iterations)):\n",
    "    im_env.reset()\n",
    "    \n",
    "    # Create agents using the Swarm-based agent creation function.\n",
    "    stage_agents = create_agents(env_config[\"stage_names\"])\n",
    "    \n",
    "    #  Run the simulation \n",
    "    total_reward = run_simulation_swarm(env_config_name, im_env, stage_agents)\n",
    "    \n",
    "    # Collect the reward from this iteration.\n",
    "    all_rewards.append(total_reward)\n",
    "    print(f\"Iteration {i+1} finished, total reward: {total_reward}\")\n",
    "\n",
    "# Print out summary statistics.\n",
    "print(\"Simulation finished.\")\n",
    "print(\"All rewards:\", all_rewards)\n",
    "print(\"Average reward:\", np.mean(all_rewards))\n",
    "print(\"Standard deviation reward:\", np.std(all_rewards))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d459f508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
