{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abdd24dd-ef40-4049-bfe1-71bffd61adae",
   "metadata": {},
   "source": [
    "## Base-stock policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80330c7-e26e-46b7-9c02-9fc5be7dbb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable demand for t=0: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 12:04:04,074\tINFO worker.py:1816 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = -296\n",
      "Episode 2: Total Reward = -296\n",
      "Episode 3: Total Reward = -296\n",
      "Episode 4: Total Reward = -296\n",
      "Episode 5: Total Reward = -296\n",
      "Episode 6: Total Reward = -296\n",
      "Episode 7: Total Reward = -296\n",
      "Episode 8: Total Reward = -296\n",
      "Episode 9: Total Reward = -296\n",
      "Episode 10: Total Reward = -296\n",
      "Episode 11: Total Reward = -296\n",
      "Episode 12: Total Reward = -296\n",
      "Episode 13: Total Reward = -296\n",
      "Episode 14: Total Reward = -296\n",
      "Episode 15: Total Reward = -296\n",
      "Episode 16: Total Reward = -296\n",
      "Episode 17: Total Reward = -296\n",
      "Episode 18: Total Reward = -296\n",
      "Episode 19: Total Reward = -296\n",
      "Episode 20: Total Reward = -296\n",
      "Episode 21: Total Reward = -296\n",
      "Episode 22: Total Reward = -296\n",
      "Episode 23: Total Reward = -296\n",
      "Episode 24: Total Reward = -296\n",
      "Episode 25: Total Reward = -296\n",
      "Episode 26: Total Reward = -296\n",
      "Episode 27: Total Reward = -296\n",
      "Episode 28: Total Reward = -296\n",
      "Episode 29: Total Reward = -296\n",
      "Episode 30: Total Reward = -296\n",
      "Episode 31: Total Reward = -296\n",
      "Episode 32: Total Reward = -296\n",
      "Episode 33: Total Reward = -296\n",
      "Episode 34: Total Reward = -296\n",
      "Episode 35: Total Reward = -296\n",
      "Episode 36: Total Reward = -296\n",
      "Episode 37: Total Reward = -296\n",
      "Episode 38: Total Reward = -296\n",
      "Episode 39: Total Reward = -296\n",
      "Episode 40: Total Reward = -296\n",
      "Episode 41: Total Reward = -296\n",
      "Episode 42: Total Reward = -296\n",
      "Episode 43: Total Reward = -296\n",
      "Episode 44: Total Reward = -296\n",
      "Episode 45: Total Reward = -296\n",
      "Episode 46: Total Reward = -296\n",
      "Episode 47: Total Reward = -296\n",
      "Episode 48: Total Reward = -296\n",
      "Episode 49: Total Reward = -296\n",
      "Episode 50: Total Reward = -296\n",
      "Episode 51: Total Reward = -296\n",
      "Episode 52: Total Reward = -296\n",
      "Episode 53: Total Reward = -296\n",
      "Episode 54: Total Reward = -296\n",
      "Episode 55: Total Reward = -296\n",
      "Episode 56: Total Reward = -296\n",
      "Episode 57: Total Reward = -296\n",
      "Episode 58: Total Reward = -296\n",
      "Episode 59: Total Reward = -296\n",
      "Episode 60: Total Reward = -296\n",
      "Episode 61: Total Reward = -296\n",
      "Episode 62: Total Reward = -296\n",
      "Episode 63: Total Reward = -296\n",
      "Episode 64: Total Reward = -296\n",
      "Episode 65: Total Reward = -296\n",
      "Episode 66: Total Reward = -296\n",
      "Episode 67: Total Reward = -296\n",
      "Episode 68: Total Reward = -296\n",
      "Episode 69: Total Reward = -296\n",
      "Episode 70: Total Reward = -296\n",
      "Episode 71: Total Reward = -296\n",
      "Episode 72: Total Reward = -296\n",
      "Episode 73: Total Reward = -296\n",
      "Episode 74: Total Reward = -296\n",
      "Episode 75: Total Reward = -296\n",
      "Episode 76: Total Reward = -296\n",
      "Episode 77: Total Reward = -296\n",
      "Episode 78: Total Reward = -296\n",
      "Episode 79: Total Reward = -296\n",
      "Episode 80: Total Reward = -296\n",
      "Episode 81: Total Reward = -296\n",
      "Episode 82: Total Reward = -296\n",
      "Episode 83: Total Reward = -296\n",
      "Episode 84: Total Reward = -296\n",
      "Episode 85: Total Reward = -296\n",
      "Episode 86: Total Reward = -296\n",
      "Episode 87: Total Reward = -296\n",
      "Episode 88: Total Reward = -296\n",
      "Episode 89: Total Reward = -296\n",
      "Episode 90: Total Reward = -296\n",
      "Episode 91: Total Reward = -296\n",
      "Episode 92: Total Reward = -296\n",
      "Episode 93: Total Reward = -296\n",
      "Episode 94: Total Reward = -296\n",
      "Episode 95: Total Reward = -296\n",
      "Episode 96: Total Reward = -296\n",
      "Episode 97: Total Reward = -296\n",
      "Episode 98: Total Reward = -296\n",
      "Episode 99: Total Reward = -296\n",
      "Episode 100: Total Reward = -296\n",
      "env_config_name = constant_demand, num_episodes = 100, episode_reward_mean = -296.00, episode_reward_std = 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 12:04:11,050\tINFO worker.py:1816 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = -486\n",
      "Episode 2: Total Reward = -600\n",
      "Episode 3: Total Reward = -554\n",
      "Episode 4: Total Reward = -484\n",
      "Episode 5: Total Reward = -582\n",
      "Episode 6: Total Reward = -461\n",
      "Episode 7: Total Reward = -454\n",
      "Episode 8: Total Reward = -580\n",
      "Episode 9: Total Reward = -525\n",
      "Episode 10: Total Reward = -496\n",
      "Episode 11: Total Reward = -583\n",
      "Episode 12: Total Reward = -612\n",
      "Episode 13: Total Reward = -458\n",
      "Episode 14: Total Reward = -634\n",
      "Episode 15: Total Reward = -592\n",
      "Episode 16: Total Reward = -515\n",
      "Episode 17: Total Reward = -461\n",
      "Episode 18: Total Reward = -510\n",
      "Episode 19: Total Reward = -564\n",
      "Episode 20: Total Reward = -595\n",
      "Episode 21: Total Reward = -485\n",
      "Episode 22: Total Reward = -484\n",
      "Episode 23: Total Reward = -553\n",
      "Episode 24: Total Reward = -515\n",
      "Episode 25: Total Reward = -521\n",
      "Episode 26: Total Reward = -502\n",
      "Episode 27: Total Reward = -484\n",
      "Episode 28: Total Reward = -500\n",
      "Episode 29: Total Reward = -619\n",
      "Episode 30: Total Reward = -556\n",
      "Episode 31: Total Reward = -490\n",
      "Episode 32: Total Reward = -563\n",
      "Episode 33: Total Reward = -493\n",
      "Episode 34: Total Reward = -474\n",
      "Episode 35: Total Reward = -536\n",
      "Episode 36: Total Reward = -536\n",
      "Episode 37: Total Reward = -413\n",
      "Episode 38: Total Reward = -550\n",
      "Episode 39: Total Reward = -512\n",
      "Episode 40: Total Reward = -475\n",
      "Episode 41: Total Reward = -497\n",
      "Episode 42: Total Reward = -530\n",
      "Episode 43: Total Reward = -497\n",
      "Episode 44: Total Reward = -612\n",
      "Episode 45: Total Reward = -408\n",
      "Episode 46: Total Reward = -536\n",
      "Episode 47: Total Reward = -516\n",
      "Episode 48: Total Reward = -521\n",
      "Episode 49: Total Reward = -562\n",
      "Episode 50: Total Reward = -484\n",
      "Episode 51: Total Reward = -514\n",
      "Episode 52: Total Reward = -484\n",
      "Episode 53: Total Reward = -457\n",
      "Episode 54: Total Reward = -576\n",
      "Episode 55: Total Reward = -518\n",
      "Episode 56: Total Reward = -478\n",
      "Episode 57: Total Reward = -490\n",
      "Episode 58: Total Reward = -483\n",
      "Episode 59: Total Reward = -474\n",
      "Episode 60: Total Reward = -636\n",
      "Episode 61: Total Reward = -390\n",
      "Episode 62: Total Reward = -537\n",
      "Episode 63: Total Reward = -548\n",
      "Episode 64: Total Reward = -491\n",
      "Episode 65: Total Reward = -598\n",
      "Episode 66: Total Reward = -497\n",
      "Episode 67: Total Reward = -578\n",
      "Episode 68: Total Reward = -597\n",
      "Episode 69: Total Reward = -546\n",
      "Episode 70: Total Reward = -548\n",
      "Episode 71: Total Reward = -506\n",
      "Episode 72: Total Reward = -520\n",
      "Episode 73: Total Reward = -544\n",
      "Episode 74: Total Reward = -512\n",
      "Episode 75: Total Reward = -495\n",
      "Episode 76: Total Reward = -569\n",
      "Episode 77: Total Reward = -508\n",
      "Episode 78: Total Reward = -627\n",
      "Episode 79: Total Reward = -507\n",
      "Episode 80: Total Reward = -574\n",
      "Episode 81: Total Reward = -497\n",
      "Episode 82: Total Reward = -537\n",
      "Episode 83: Total Reward = -544\n",
      "Episode 84: Total Reward = -513\n",
      "Episode 85: Total Reward = -549\n",
      "Episode 86: Total Reward = -538\n",
      "Episode 87: Total Reward = -526\n",
      "Episode 88: Total Reward = -487\n",
      "Episode 89: Total Reward = -495\n",
      "Episode 90: Total Reward = -596\n",
      "Episode 91: Total Reward = -426\n",
      "Episode 92: Total Reward = -515\n",
      "Episode 93: Total Reward = -524\n",
      "Episode 94: Total Reward = -507\n",
      "Episode 95: Total Reward = -469\n",
      "Episode 96: Total Reward = -539\n",
      "Episode 97: Total Reward = -488\n",
      "Episode 98: Total Reward = -556\n",
      "Episode 99: Total Reward = -537\n",
      "Episode 100: Total Reward = -554\n",
      "env_config_name = variable_demand, num_episodes = 100, episode_reward_mean = -523.69, episode_reward_std = 49.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 12:04:17,775\tINFO worker.py:1816 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = -404\n",
      "Episode 2: Total Reward = -271\n",
      "Episode 3: Total Reward = -532\n",
      "Episode 4: Total Reward = -588\n",
      "Episode 5: Total Reward = -366\n",
      "Episode 6: Total Reward = -446\n",
      "Episode 7: Total Reward = -435\n",
      "Episode 8: Total Reward = -645\n",
      "Episode 9: Total Reward = -604\n",
      "Episode 10: Total Reward = -522\n",
      "Episode 11: Total Reward = -284\n",
      "Episode 12: Total Reward = -400\n",
      "Episode 13: Total Reward = -397\n",
      "Episode 14: Total Reward = -257\n",
      "Episode 15: Total Reward = -281\n",
      "Episode 16: Total Reward = -356\n",
      "Episode 17: Total Reward = -391\n",
      "Episode 18: Total Reward = -552\n",
      "Episode 19: Total Reward = -605\n",
      "Episode 20: Total Reward = -326\n",
      "Episode 21: Total Reward = -628\n",
      "Episode 22: Total Reward = -289\n",
      "Episode 23: Total Reward = -430\n",
      "Episode 24: Total Reward = -316\n",
      "Episode 25: Total Reward = -427\n",
      "Episode 26: Total Reward = -381\n",
      "Episode 27: Total Reward = -346\n",
      "Episode 28: Total Reward = -341\n",
      "Episode 29: Total Reward = -349\n",
      "Episode 30: Total Reward = -600\n",
      "Episode 31: Total Reward = -529\n",
      "Episode 32: Total Reward = -424\n",
      "Episode 33: Total Reward = -323\n",
      "Episode 34: Total Reward = -399\n",
      "Episode 35: Total Reward = -420\n",
      "Episode 36: Total Reward = -509\n",
      "Episode 37: Total Reward = -449\n",
      "Episode 38: Total Reward = -357\n",
      "Episode 39: Total Reward = -580\n",
      "Episode 40: Total Reward = -340\n",
      "Episode 41: Total Reward = -353\n",
      "Episode 42: Total Reward = -366\n",
      "Episode 43: Total Reward = -379\n",
      "Episode 44: Total Reward = -390\n",
      "Episode 45: Total Reward = -518\n",
      "Episode 46: Total Reward = -540\n",
      "Episode 47: Total Reward = -543\n",
      "Episode 48: Total Reward = -435\n",
      "Episode 49: Total Reward = -418\n",
      "Episode 50: Total Reward = -396\n",
      "Episode 51: Total Reward = -559\n",
      "Episode 52: Total Reward = -339\n",
      "Episode 53: Total Reward = -385\n",
      "Episode 54: Total Reward = -553\n",
      "Episode 55: Total Reward = -439\n",
      "Episode 56: Total Reward = -566\n",
      "Episode 57: Total Reward = -426\n",
      "Episode 58: Total Reward = -403\n",
      "Episode 59: Total Reward = -449\n",
      "Episode 60: Total Reward = -365\n",
      "Episode 61: Total Reward = -405\n",
      "Episode 62: Total Reward = -308\n",
      "Episode 63: Total Reward = -352\n",
      "Episode 64: Total Reward = -343\n",
      "Episode 65: Total Reward = -356\n",
      "Episode 66: Total Reward = -522\n",
      "Episode 67: Total Reward = -572\n",
      "Episode 68: Total Reward = -352\n",
      "Episode 69: Total Reward = -266\n",
      "Episode 70: Total Reward = -426\n",
      "Episode 71: Total Reward = -369\n",
      "Episode 72: Total Reward = -642\n",
      "Episode 73: Total Reward = -413\n",
      "Episode 74: Total Reward = -677\n",
      "Episode 75: Total Reward = -196\n",
      "Episode 76: Total Reward = -647\n",
      "Episode 77: Total Reward = -396\n",
      "Episode 78: Total Reward = -405\n",
      "Episode 79: Total Reward = -548\n",
      "Episode 80: Total Reward = -458\n",
      "Episode 81: Total Reward = -347\n",
      "Episode 82: Total Reward = -397\n",
      "Episode 83: Total Reward = -724\n",
      "Episode 84: Total Reward = -402\n",
      "Episode 85: Total Reward = -423\n",
      "Episode 86: Total Reward = -599\n",
      "Episode 87: Total Reward = -711\n",
      "Episode 88: Total Reward = -437\n",
      "Episode 89: Total Reward = -398\n",
      "Episode 90: Total Reward = -189\n",
      "Episode 91: Total Reward = -348\n",
      "Episode 92: Total Reward = -507\n",
      "Episode 93: Total Reward = -438\n",
      "Episode 94: Total Reward = -540\n",
      "Episode 95: Total Reward = -626\n",
      "Episode 96: Total Reward = -417\n",
      "Episode 97: Total Reward = -463\n",
      "Episode 98: Total Reward = -564\n",
      "Episode 99: Total Reward = -473\n",
      "Episode 100: Total Reward = -409\n",
      "env_config_name = larger_demand, num_episodes = 100, episode_reward_mean = -439.86, episode_reward_std = 112.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 12:04:24,938\tINFO worker.py:1816 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = -203\n",
      "Episode 2: Total Reward = -278\n",
      "Episode 3: Total Reward = -279\n",
      "Episode 4: Total Reward = -278\n",
      "Episode 5: Total Reward = -311\n",
      "Episode 6: Total Reward = -327\n",
      "Episode 7: Total Reward = -294\n",
      "Episode 8: Total Reward = -262\n",
      "Episode 9: Total Reward = -230\n",
      "Episode 10: Total Reward = -309\n",
      "Episode 11: Total Reward = -235\n",
      "Episode 12: Total Reward = -261\n",
      "Episode 13: Total Reward = -213\n",
      "Episode 14: Total Reward = -233\n",
      "Episode 15: Total Reward = -327\n",
      "Episode 16: Total Reward = -281\n",
      "Episode 17: Total Reward = -229\n",
      "Episode 18: Total Reward = -367\n",
      "Episode 19: Total Reward = -300\n",
      "Episode 20: Total Reward = -329\n",
      "Episode 21: Total Reward = -282\n",
      "Episode 22: Total Reward = -286\n",
      "Episode 23: Total Reward = -251\n",
      "Episode 24: Total Reward = -250\n",
      "Episode 25: Total Reward = -307\n",
      "Episode 26: Total Reward = -276\n",
      "Episode 27: Total Reward = -360\n",
      "Episode 28: Total Reward = -270\n",
      "Episode 29: Total Reward = -196\n",
      "Episode 30: Total Reward = -235\n",
      "Episode 31: Total Reward = -258\n",
      "Episode 32: Total Reward = -223\n",
      "Episode 33: Total Reward = -348\n",
      "Episode 34: Total Reward = -284\n",
      "Episode 35: Total Reward = -337\n",
      "Episode 36: Total Reward = -230\n",
      "Episode 37: Total Reward = -191\n",
      "Episode 38: Total Reward = -254\n",
      "Episode 39: Total Reward = -363\n",
      "Episode 40: Total Reward = -277\n",
      "Episode 41: Total Reward = -244\n",
      "Episode 42: Total Reward = -333\n",
      "Episode 43: Total Reward = -362\n",
      "Episode 44: Total Reward = -240\n",
      "Episode 45: Total Reward = -280\n",
      "Episode 46: Total Reward = -282\n",
      "Episode 47: Total Reward = -266\n",
      "Episode 48: Total Reward = -226\n",
      "Episode 49: Total Reward = -253\n",
      "Episode 50: Total Reward = -270\n",
      "Episode 51: Total Reward = -277\n",
      "Episode 52: Total Reward = -267\n",
      "Episode 53: Total Reward = -236\n",
      "Episode 54: Total Reward = -294\n",
      "Episode 55: Total Reward = -251\n",
      "Episode 56: Total Reward = -275\n",
      "Episode 57: Total Reward = -338\n",
      "Episode 58: Total Reward = -233\n",
      "Episode 59: Total Reward = -218\n",
      "Episode 60: Total Reward = -314\n",
      "Episode 61: Total Reward = -231\n",
      "Episode 62: Total Reward = -229\n",
      "Episode 63: Total Reward = -290\n",
      "Episode 64: Total Reward = -288\n",
      "Episode 65: Total Reward = -253\n",
      "Episode 66: Total Reward = -311\n",
      "Episode 67: Total Reward = -266\n",
      "Episode 68: Total Reward = -274\n",
      "Episode 69: Total Reward = -287\n",
      "Episode 70: Total Reward = -272\n",
      "Episode 71: Total Reward = -290\n",
      "Episode 72: Total Reward = -242\n",
      "Episode 73: Total Reward = -226\n",
      "Episode 74: Total Reward = -255\n",
      "Episode 75: Total Reward = -251\n",
      "Episode 76: Total Reward = -247\n",
      "Episode 77: Total Reward = -321\n",
      "Episode 78: Total Reward = -346\n",
      "Episode 79: Total Reward = -284\n",
      "Episode 80: Total Reward = -253\n",
      "Episode 81: Total Reward = -291\n",
      "Episode 82: Total Reward = -347\n",
      "Episode 83: Total Reward = -241\n",
      "Episode 84: Total Reward = -278\n",
      "Episode 85: Total Reward = -347\n",
      "Episode 86: Total Reward = -352\n",
      "Episode 87: Total Reward = -262\n",
      "Episode 88: Total Reward = -275\n",
      "Episode 89: Total Reward = -311\n",
      "Episode 90: Total Reward = -206\n",
      "Episode 91: Total Reward = -267\n",
      "Episode 92: Total Reward = -269\n",
      "Episode 93: Total Reward = -242\n",
      "Episode 94: Total Reward = -291\n",
      "Episode 95: Total Reward = -240\n",
      "Episode 96: Total Reward = -292\n",
      "Episode 97: Total Reward = -220\n",
      "Episode 98: Total Reward = -278\n",
      "Episode 99: Total Reward = -224\n",
      "Episode 100: Total Reward = -297\n",
      "env_config_name = seasonal_demand, num_episodes = 100, episode_reward_mean = -274.29, episode_reward_std = 40.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 12:04:31,920\tINFO worker.py:1816 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = -92\n",
      "Episode 2: Total Reward = -284\n",
      "Episode 3: Total Reward = -251\n",
      "Episode 4: Total Reward = -382\n",
      "Episode 5: Total Reward = -479\n",
      "Episode 6: Total Reward = -481\n",
      "Episode 7: Total Reward = -433\n",
      "Episode 8: Total Reward = -114\n",
      "Episode 9: Total Reward = -249\n",
      "Episode 10: Total Reward = -66\n",
      "Episode 11: Total Reward = -258\n",
      "Episode 12: Total Reward = -353\n",
      "Episode 13: Total Reward = -274\n",
      "Episode 14: Total Reward = -371\n",
      "Episode 15: Total Reward = -298\n",
      "Episode 16: Total Reward = -522\n",
      "Episode 17: Total Reward = -163\n",
      "Episode 18: Total Reward = -356\n",
      "Episode 19: Total Reward = -322\n",
      "Episode 20: Total Reward = -424\n",
      "Episode 21: Total Reward = -416\n",
      "Episode 22: Total Reward = -449\n",
      "Episode 23: Total Reward = -327\n",
      "Episode 24: Total Reward = -214\n",
      "Episode 25: Total Reward = -192\n",
      "Episode 26: Total Reward = -349\n",
      "Episode 27: Total Reward = -471\n",
      "Episode 28: Total Reward = -344\n",
      "Episode 29: Total Reward = -371\n",
      "Episode 30: Total Reward = -430\n",
      "Episode 31: Total Reward = -315\n",
      "Episode 32: Total Reward = -418\n",
      "Episode 33: Total Reward = -427\n",
      "Episode 34: Total Reward = -250\n",
      "Episode 35: Total Reward = -213\n",
      "Episode 36: Total Reward = -387\n",
      "Episode 37: Total Reward = -279\n",
      "Episode 38: Total Reward = -299\n",
      "Episode 39: Total Reward = -432\n",
      "Episode 40: Total Reward = -356\n",
      "Episode 41: Total Reward = -271\n",
      "Episode 42: Total Reward = -222\n",
      "Episode 43: Total Reward = -521\n",
      "Episode 44: Total Reward = -278\n",
      "Episode 45: Total Reward = -435\n",
      "Episode 46: Total Reward = -288\n",
      "Episode 47: Total Reward = -350\n",
      "Episode 48: Total Reward = -262\n",
      "Episode 49: Total Reward = -488\n",
      "Episode 50: Total Reward = -422\n",
      "Episode 51: Total Reward = -576\n",
      "Episode 52: Total Reward = -255\n",
      "Episode 53: Total Reward = -342\n",
      "Episode 54: Total Reward = -245\n",
      "Episode 55: Total Reward = -346\n",
      "Episode 56: Total Reward = -478\n",
      "Episode 57: Total Reward = -278\n",
      "Episode 58: Total Reward = -389\n",
      "Episode 59: Total Reward = -285\n",
      "Episode 60: Total Reward = -280\n",
      "Episode 61: Total Reward = -411\n",
      "Episode 62: Total Reward = -450\n",
      "Episode 63: Total Reward = -288\n",
      "Episode 64: Total Reward = -345\n",
      "Episode 65: Total Reward = -399\n",
      "Episode 66: Total Reward = -293\n",
      "Episode 67: Total Reward = -357\n",
      "Episode 68: Total Reward = -287\n",
      "Episode 69: Total Reward = -308\n",
      "Episode 70: Total Reward = -256\n",
      "Episode 71: Total Reward = -306\n",
      "Episode 72: Total Reward = -447\n",
      "Episode 73: Total Reward = -384\n",
      "Episode 74: Total Reward = -424\n",
      "Episode 75: Total Reward = -333\n",
      "Episode 76: Total Reward = -374\n",
      "Episode 77: Total Reward = -336\n",
      "Episode 78: Total Reward = -206\n",
      "Episode 79: Total Reward = -183\n",
      "Episode 80: Total Reward = -215\n",
      "Episode 81: Total Reward = -179\n",
      "Episode 82: Total Reward = -228\n",
      "Episode 83: Total Reward = -272\n",
      "Episode 84: Total Reward = -316\n",
      "Episode 85: Total Reward = -306\n",
      "Episode 86: Total Reward = -330\n",
      "Episode 87: Total Reward = -167\n",
      "Episode 88: Total Reward = -231\n",
      "Episode 89: Total Reward = -353\n",
      "Episode 90: Total Reward = -428\n",
      "Episode 91: Total Reward = -415\n",
      "Episode 92: Total Reward = -305\n",
      "Episode 93: Total Reward = -145\n",
      "Episode 94: Total Reward = -231\n",
      "Episode 95: Total Reward = -331\n",
      "Episode 96: Total Reward = -385\n",
      "Episode 97: Total Reward = -161\n",
      "Episode 98: Total Reward = -179\n",
      "Episode 99: Total Reward = -298\n",
      "Episode 100: Total Reward = -260\n",
      "env_config_name = normal_demand, num_episodes = 100, episode_reward_mean = -322.44, episode_reward_std = 99.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 12:04:38,946\tINFO worker.py:1816 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 43\n",
      "Episode 2: Total Reward = 43\n",
      "Episode 3: Total Reward = 43\n",
      "Episode 4: Total Reward = 43\n",
      "Episode 5: Total Reward = 43\n",
      "Episode 6: Total Reward = 43\n",
      "Episode 7: Total Reward = 43\n",
      "Episode 8: Total Reward = 43\n",
      "Episode 9: Total Reward = 43\n",
      "Episode 10: Total Reward = 43\n",
      "Episode 11: Total Reward = 43\n",
      "Episode 12: Total Reward = 43\n",
      "Episode 13: Total Reward = 43\n",
      "Episode 14: Total Reward = 43\n",
      "Episode 15: Total Reward = 43\n",
      "Episode 16: Total Reward = 43\n",
      "Episode 17: Total Reward = 43\n",
      "Episode 18: Total Reward = 43\n",
      "Episode 19: Total Reward = 43\n",
      "Episode 20: Total Reward = 43\n",
      "Episode 21: Total Reward = 43\n",
      "Episode 22: Total Reward = 43\n",
      "Episode 23: Total Reward = 43\n",
      "Episode 24: Total Reward = 43\n",
      "Episode 25: Total Reward = 43\n",
      "Episode 26: Total Reward = 43\n",
      "Episode 27: Total Reward = 43\n",
      "Episode 28: Total Reward = 43\n",
      "Episode 29: Total Reward = 43\n",
      "Episode 30: Total Reward = 43\n",
      "Episode 31: Total Reward = 43\n",
      "Episode 32: Total Reward = 43\n",
      "Episode 33: Total Reward = 43\n",
      "Episode 34: Total Reward = 43\n",
      "Episode 35: Total Reward = 43\n",
      "Episode 36: Total Reward = 43\n",
      "Episode 37: Total Reward = 43\n",
      "Episode 38: Total Reward = 43\n",
      "Episode 39: Total Reward = 43\n",
      "Episode 40: Total Reward = 43\n",
      "Episode 41: Total Reward = 43\n",
      "Episode 42: Total Reward = 43\n",
      "Episode 43: Total Reward = 43\n",
      "Episode 44: Total Reward = 43\n",
      "Episode 45: Total Reward = 43\n",
      "Episode 46: Total Reward = 43\n",
      "Episode 47: Total Reward = 43\n",
      "Episode 48: Total Reward = 43\n",
      "Episode 49: Total Reward = 43\n",
      "Episode 50: Total Reward = 43\n",
      "Episode 51: Total Reward = 43\n",
      "Episode 52: Total Reward = 43\n",
      "Episode 53: Total Reward = 43\n",
      "Episode 54: Total Reward = 43\n",
      "Episode 55: Total Reward = 43\n",
      "Episode 56: Total Reward = 43\n",
      "Episode 57: Total Reward = 43\n",
      "Episode 58: Total Reward = 43\n",
      "Episode 59: Total Reward = 43\n",
      "Episode 60: Total Reward = 43\n",
      "Episode 61: Total Reward = 43\n",
      "Episode 62: Total Reward = 43\n",
      "Episode 63: Total Reward = 43\n",
      "Episode 64: Total Reward = 43\n",
      "Episode 65: Total Reward = 43\n",
      "Episode 66: Total Reward = 43\n",
      "Episode 67: Total Reward = 43\n",
      "Episode 68: Total Reward = 43\n",
      "Episode 69: Total Reward = 43\n",
      "Episode 70: Total Reward = 43\n",
      "Episode 71: Total Reward = 43\n",
      "Episode 72: Total Reward = 43\n",
      "Episode 73: Total Reward = 43\n",
      "Episode 74: Total Reward = 43\n",
      "Episode 75: Total Reward = 43\n",
      "Episode 76: Total Reward = 43\n",
      "Episode 77: Total Reward = 43\n",
      "Episode 78: Total Reward = 43\n",
      "Episode 79: Total Reward = 43\n",
      "Episode 80: Total Reward = 43\n",
      "Episode 81: Total Reward = 43\n",
      "Episode 82: Total Reward = 43\n",
      "Episode 83: Total Reward = 43\n",
      "Episode 84: Total Reward = 43\n",
      "Episode 85: Total Reward = 43\n",
      "Episode 86: Total Reward = 43\n",
      "Episode 87: Total Reward = 43\n",
      "Episode 88: Total Reward = 43\n",
      "Episode 89: Total Reward = 43\n",
      "Episode 90: Total Reward = 43\n",
      "Episode 91: Total Reward = 43\n",
      "Episode 92: Total Reward = 43\n",
      "Episode 93: Total Reward = 43\n",
      "Episode 94: Total Reward = 43\n",
      "Episode 95: Total Reward = 43\n",
      "Episode 96: Total Reward = 43\n",
      "Episode 97: Total Reward = 43\n",
      "Episode 98: Total Reward = 43\n",
      "Episode 99: Total Reward = 43\n",
      "Episode 100: Total Reward = 43\n",
      "env_config_name = increasing_demand, num_episodes = 100, episode_reward_mean = 43.00, episode_reward_std = 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 12:04:46,038\tINFO worker.py:1816 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = -679\n",
      "Episode 2: Total Reward = -679\n",
      "Episode 3: Total Reward = -679\n",
      "Episode 4: Total Reward = -679\n",
      "Episode 5: Total Reward = -679\n",
      "Episode 6: Total Reward = -679\n",
      "Episode 7: Total Reward = -679\n",
      "Episode 8: Total Reward = -679\n",
      "Episode 9: Total Reward = -679\n",
      "Episode 10: Total Reward = -679\n",
      "Episode 11: Total Reward = -679\n",
      "Episode 12: Total Reward = -679\n",
      "Episode 13: Total Reward = -679\n",
      "Episode 14: Total Reward = -679\n",
      "Episode 15: Total Reward = -679\n",
      "Episode 16: Total Reward = -679\n",
      "Episode 17: Total Reward = -679\n",
      "Episode 18: Total Reward = -679\n",
      "Episode 19: Total Reward = -679\n",
      "Episode 20: Total Reward = -679\n",
      "Episode 21: Total Reward = -679\n",
      "Episode 22: Total Reward = -679\n",
      "Episode 23: Total Reward = -679\n",
      "Episode 24: Total Reward = -679\n",
      "Episode 25: Total Reward = -679\n",
      "Episode 26: Total Reward = -679\n",
      "Episode 27: Total Reward = -679\n",
      "Episode 28: Total Reward = -679\n",
      "Episode 29: Total Reward = -679\n",
      "Episode 30: Total Reward = -679\n",
      "Episode 31: Total Reward = -679\n",
      "Episode 32: Total Reward = -679\n",
      "Episode 33: Total Reward = -679\n",
      "Episode 34: Total Reward = -679\n",
      "Episode 35: Total Reward = -679\n",
      "Episode 36: Total Reward = -679\n",
      "Episode 37: Total Reward = -679\n",
      "Episode 38: Total Reward = -679\n",
      "Episode 39: Total Reward = -679\n",
      "Episode 40: Total Reward = -679\n",
      "Episode 41: Total Reward = -679\n",
      "Episode 42: Total Reward = -679\n",
      "Episode 43: Total Reward = -679\n",
      "Episode 44: Total Reward = -679\n",
      "Episode 45: Total Reward = -679\n",
      "Episode 46: Total Reward = -679\n",
      "Episode 47: Total Reward = -679\n",
      "Episode 48: Total Reward = -679\n",
      "Episode 49: Total Reward = -679\n",
      "Episode 50: Total Reward = -679\n",
      "Episode 51: Total Reward = -679\n",
      "Episode 52: Total Reward = -679\n",
      "Episode 53: Total Reward = -679\n",
      "Episode 54: Total Reward = -679\n",
      "Episode 55: Total Reward = -679\n",
      "Episode 56: Total Reward = -679\n",
      "Episode 57: Total Reward = -679\n",
      "Episode 58: Total Reward = -679\n",
      "Episode 59: Total Reward = -679\n",
      "Episode 60: Total Reward = -679\n",
      "Episode 61: Total Reward = -679\n",
      "Episode 62: Total Reward = -679\n",
      "Episode 63: Total Reward = -679\n",
      "Episode 64: Total Reward = -679\n",
      "Episode 65: Total Reward = -679\n",
      "Episode 66: Total Reward = -679\n",
      "Episode 67: Total Reward = -679\n",
      "Episode 68: Total Reward = -679\n",
      "Episode 69: Total Reward = -679\n",
      "Episode 70: Total Reward = -679\n",
      "Episode 71: Total Reward = -679\n",
      "Episode 72: Total Reward = -679\n",
      "Episode 73: Total Reward = -679\n",
      "Episode 74: Total Reward = -679\n",
      "Episode 75: Total Reward = -679\n",
      "Episode 76: Total Reward = -679\n",
      "Episode 77: Total Reward = -679\n",
      "Episode 78: Total Reward = -679\n",
      "Episode 79: Total Reward = -679\n",
      "Episode 80: Total Reward = -679\n",
      "Episode 81: Total Reward = -679\n",
      "Episode 82: Total Reward = -679\n",
      "Episode 83: Total Reward = -679\n",
      "Episode 84: Total Reward = -679\n",
      "Episode 85: Total Reward = -679\n",
      "Episode 86: Total Reward = -679\n",
      "Episode 87: Total Reward = -679\n",
      "Episode 88: Total Reward = -679\n",
      "Episode 89: Total Reward = -679\n",
      "Episode 90: Total Reward = -679\n",
      "Episode 91: Total Reward = -679\n",
      "Episode 92: Total Reward = -679\n",
      "Episode 93: Total Reward = -679\n",
      "Episode 94: Total Reward = -679\n",
      "Episode 95: Total Reward = -679\n",
      "Episode 96: Total Reward = -679\n",
      "Episode 97: Total Reward = -679\n",
      "Episode 98: Total Reward = -679\n",
      "Episode 99: Total Reward = -679\n",
      "Episode 100: Total Reward = -679\n",
      "env_config_name = cyclical_demand, num_episodes = 100, episode_reward_mean = -679.00, episode_reward_std = 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 12:04:52,787\tINFO worker.py:1816 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = -364\n",
      "Episode 2: Total Reward = -364\n",
      "Episode 3: Total Reward = -364\n",
      "Episode 4: Total Reward = -364\n",
      "Episode 5: Total Reward = -364\n",
      "Episode 6: Total Reward = -364\n",
      "Episode 7: Total Reward = -364\n",
      "Episode 8: Total Reward = -364\n",
      "Episode 9: Total Reward = -364\n",
      "Episode 10: Total Reward = -364\n",
      "Episode 11: Total Reward = -364\n",
      "Episode 12: Total Reward = -364\n",
      "Episode 13: Total Reward = -364\n",
      "Episode 14: Total Reward = -364\n",
      "Episode 15: Total Reward = -364\n",
      "Episode 16: Total Reward = -364\n",
      "Episode 17: Total Reward = -364\n",
      "Episode 18: Total Reward = -364\n",
      "Episode 19: Total Reward = -364\n",
      "Episode 20: Total Reward = -364\n",
      "Episode 21: Total Reward = -364\n",
      "Episode 22: Total Reward = -364\n",
      "Episode 23: Total Reward = -364\n",
      "Episode 24: Total Reward = -364\n",
      "Episode 25: Total Reward = -364\n",
      "Episode 26: Total Reward = -364\n",
      "Episode 27: Total Reward = -364\n",
      "Episode 28: Total Reward = -364\n",
      "Episode 29: Total Reward = -364\n",
      "Episode 30: Total Reward = -364\n",
      "Episode 31: Total Reward = -364\n",
      "Episode 32: Total Reward = -364\n",
      "Episode 33: Total Reward = -364\n",
      "Episode 34: Total Reward = -364\n",
      "Episode 35: Total Reward = -364\n",
      "Episode 36: Total Reward = -364\n",
      "Episode 37: Total Reward = -364\n",
      "Episode 38: Total Reward = -364\n",
      "Episode 39: Total Reward = -364\n",
      "Episode 40: Total Reward = -364\n",
      "Episode 41: Total Reward = -364\n",
      "Episode 42: Total Reward = -364\n",
      "Episode 43: Total Reward = -364\n",
      "Episode 44: Total Reward = -364\n",
      "Episode 45: Total Reward = -364\n",
      "Episode 46: Total Reward = -364\n",
      "Episode 47: Total Reward = -364\n",
      "Episode 48: Total Reward = -364\n",
      "Episode 49: Total Reward = -364\n",
      "Episode 50: Total Reward = -364\n",
      "Episode 51: Total Reward = -364\n",
      "Episode 52: Total Reward = -364\n",
      "Episode 53: Total Reward = -364\n",
      "Episode 54: Total Reward = -364\n",
      "Episode 55: Total Reward = -364\n",
      "Episode 56: Total Reward = -364\n",
      "Episode 57: Total Reward = -364\n",
      "Episode 58: Total Reward = -364\n",
      "Episode 59: Total Reward = -364\n",
      "Episode 60: Total Reward = -364\n",
      "Episode 61: Total Reward = -364\n",
      "Episode 62: Total Reward = -364\n",
      "Episode 63: Total Reward = -364\n",
      "Episode 64: Total Reward = -364\n",
      "Episode 65: Total Reward = -364\n",
      "Episode 66: Total Reward = -364\n",
      "Episode 67: Total Reward = -364\n",
      "Episode 68: Total Reward = -364\n",
      "Episode 69: Total Reward = -364\n",
      "Episode 70: Total Reward = -364\n",
      "Episode 71: Total Reward = -364\n",
      "Episode 72: Total Reward = -364\n",
      "Episode 73: Total Reward = -364\n",
      "Episode 74: Total Reward = -364\n",
      "Episode 75: Total Reward = -364\n",
      "Episode 76: Total Reward = -364\n",
      "Episode 77: Total Reward = -364\n",
      "Episode 78: Total Reward = -364\n",
      "Episode 79: Total Reward = -364\n",
      "Episode 80: Total Reward = -364\n",
      "Episode 81: Total Reward = -364\n",
      "Episode 82: Total Reward = -364\n",
      "Episode 83: Total Reward = -364\n",
      "Episode 84: Total Reward = -364\n",
      "Episode 85: Total Reward = -364\n",
      "Episode 86: Total Reward = -364\n",
      "Episode 87: Total Reward = -364\n",
      "Episode 88: Total Reward = -364\n",
      "Episode 89: Total Reward = -364\n",
      "Episode 90: Total Reward = -364\n",
      "Episode 91: Total Reward = -364\n",
      "Episode 92: Total Reward = -364\n",
      "Episode 93: Total Reward = -364\n",
      "Episode 94: Total Reward = -364\n",
      "Episode 95: Total Reward = -364\n",
      "Episode 96: Total Reward = -364\n",
      "Episode 97: Total Reward = -364\n",
      "Episode 98: Total Reward = -364\n",
      "Episode 99: Total Reward = -364\n",
      "Episode 100: Total Reward = -364\n",
      "env_config_name = demand_shock, num_episodes = 100, episode_reward_mean = -364.00, episode_reward_std = 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 12:04:59,493\tINFO worker.py:1816 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Generating a new stochastic demand series...\n",
      "Episode 1: Total Reward = -342\n",
      "Episode 2: Generating a new stochastic demand series...\n",
      "Episode 2: Total Reward = -656\n",
      "Episode 3: Generating a new stochastic demand series...\n",
      "Episode 3: Total Reward = -326\n",
      "Episode 4: Generating a new stochastic demand series...\n",
      "Episode 4: Total Reward = -512\n",
      "Episode 5: Generating a new stochastic demand series...\n",
      "Episode 5: Total Reward = -494\n",
      "Episode 6: Generating a new stochastic demand series...\n",
      "Episode 6: Total Reward = -382\n",
      "Episode 7: Generating a new stochastic demand series...\n",
      "Episode 7: Total Reward = -593\n",
      "Episode 8: Generating a new stochastic demand series...\n",
      "Episode 8: Total Reward = -227\n",
      "Episode 9: Generating a new stochastic demand series...\n",
      "Episode 9: Total Reward = -554\n",
      "Episode 10: Generating a new stochastic demand series...\n",
      "Episode 10: Total Reward = -321\n",
      "Episode 11: Generating a new stochastic demand series...\n",
      "Episode 11: Total Reward = -526\n",
      "Episode 12: Generating a new stochastic demand series...\n",
      "Episode 12: Total Reward = -438\n",
      "Episode 13: Generating a new stochastic demand series...\n",
      "Episode 13: Total Reward = -388\n",
      "Episode 14: Generating a new stochastic demand series...\n",
      "Episode 14: Total Reward = -675\n",
      "Episode 15: Generating a new stochastic demand series...\n",
      "Episode 15: Total Reward = -451\n",
      "Episode 16: Generating a new stochastic demand series...\n",
      "Episode 16: Total Reward = -415\n",
      "Episode 17: Generating a new stochastic demand series...\n",
      "Episode 17: Total Reward = -444\n",
      "Episode 18: Generating a new stochastic demand series...\n",
      "Episode 18: Total Reward = -405\n",
      "Episode 19: Generating a new stochastic demand series...\n",
      "Episode 19: Total Reward = -547\n",
      "Episode 20: Generating a new stochastic demand series...\n",
      "Episode 20: Total Reward = -400\n",
      "Episode 21: Generating a new stochastic demand series...\n",
      "Episode 21: Total Reward = -475\n",
      "Episode 22: Generating a new stochastic demand series...\n",
      "Episode 22: Total Reward = -559\n",
      "Episode 23: Generating a new stochastic demand series...\n",
      "Episode 23: Total Reward = -451\n",
      "Episode 24: Generating a new stochastic demand series...\n",
      "Episode 24: Total Reward = -367\n",
      "Episode 25: Generating a new stochastic demand series...\n",
      "Episode 25: Total Reward = -553\n",
      "Episode 26: Generating a new stochastic demand series...\n",
      "Episode 26: Total Reward = -357\n",
      "Episode 27: Generating a new stochastic demand series...\n",
      "Episode 27: Total Reward = -287\n",
      "Episode 28: Generating a new stochastic demand series...\n",
      "Episode 28: Total Reward = -545\n",
      "Episode 29: Generating a new stochastic demand series...\n",
      "Episode 29: Total Reward = -178\n",
      "Episode 30: Generating a new stochastic demand series...\n",
      "Episode 30: Total Reward = -347\n",
      "Episode 31: Generating a new stochastic demand series...\n",
      "Episode 31: Total Reward = -412\n",
      "Episode 32: Generating a new stochastic demand series...\n",
      "Episode 32: Total Reward = -477\n",
      "Episode 33: Generating a new stochastic demand series...\n",
      "Episode 33: Total Reward = -414\n",
      "Episode 34: Generating a new stochastic demand series...\n",
      "Episode 34: Total Reward = -617\n",
      "Episode 35: Generating a new stochastic demand series...\n",
      "Episode 35: Total Reward = -390\n",
      "Episode 36: Generating a new stochastic demand series...\n",
      "Episode 36: Total Reward = -156\n",
      "Episode 37: Generating a new stochastic demand series...\n",
      "Episode 37: Total Reward = -622\n",
      "Episode 38: Generating a new stochastic demand series...\n",
      "Episode 38: Total Reward = -494\n",
      "Episode 39: Generating a new stochastic demand series...\n",
      "Episode 39: Total Reward = -560\n",
      "Episode 40: Generating a new stochastic demand series...\n",
      "Episode 40: Total Reward = -527\n",
      "Episode 41: Generating a new stochastic demand series...\n",
      "Episode 41: Total Reward = -438\n",
      "Episode 42: Generating a new stochastic demand series...\n",
      "Episode 42: Total Reward = -315\n",
      "Episode 43: Generating a new stochastic demand series...\n",
      "Episode 43: Total Reward = -300\n",
      "Episode 44: Generating a new stochastic demand series...\n",
      "Episode 44: Total Reward = -439\n",
      "Episode 45: Generating a new stochastic demand series...\n",
      "Episode 45: Total Reward = -251\n",
      "Episode 46: Generating a new stochastic demand series...\n",
      "Episode 46: Total Reward = -530\n",
      "Episode 47: Generating a new stochastic demand series...\n",
      "Episode 47: Total Reward = -604\n",
      "Episode 48: Generating a new stochastic demand series...\n",
      "Episode 48: Total Reward = -557\n",
      "Episode 49: Generating a new stochastic demand series...\n",
      "Episode 49: Total Reward = -314\n",
      "Episode 50: Generating a new stochastic demand series...\n",
      "Episode 50: Total Reward = -316\n",
      "Episode 51: Generating a new stochastic demand series...\n",
      "Episode 51: Total Reward = -482\n",
      "Episode 52: Generating a new stochastic demand series...\n",
      "Episode 52: Total Reward = -340\n",
      "Episode 53: Generating a new stochastic demand series...\n",
      "Episode 53: Total Reward = -393\n",
      "Episode 54: Generating a new stochastic demand series...\n",
      "Episode 54: Total Reward = -615\n",
      "Episode 55: Generating a new stochastic demand series...\n",
      "Episode 55: Total Reward = -478\n",
      "Episode 56: Generating a new stochastic demand series...\n",
      "Episode 56: Total Reward = -328\n",
      "Episode 57: Generating a new stochastic demand series...\n",
      "Episode 57: Total Reward = -407\n",
      "Episode 58: Generating a new stochastic demand series...\n",
      "Episode 58: Total Reward = -645\n",
      "Episode 59: Generating a new stochastic demand series...\n",
      "Episode 59: Total Reward = -471\n",
      "Episode 60: Generating a new stochastic demand series...\n",
      "Episode 60: Total Reward = -363\n",
      "Episode 61: Generating a new stochastic demand series...\n",
      "Episode 61: Total Reward = -470\n",
      "Episode 62: Generating a new stochastic demand series...\n",
      "Episode 62: Total Reward = -571\n",
      "Episode 63: Generating a new stochastic demand series...\n",
      "Episode 63: Total Reward = -596\n",
      "Episode 64: Generating a new stochastic demand series...\n",
      "Episode 64: Total Reward = -405\n",
      "Episode 65: Generating a new stochastic demand series...\n",
      "Episode 65: Total Reward = -375\n",
      "Episode 66: Generating a new stochastic demand series...\n",
      "Episode 66: Total Reward = -317\n",
      "Episode 67: Generating a new stochastic demand series...\n",
      "Episode 67: Total Reward = -442\n",
      "Episode 68: Generating a new stochastic demand series...\n",
      "Episode 68: Total Reward = -408\n",
      "Episode 69: Generating a new stochastic demand series...\n",
      "Episode 69: Total Reward = -658\n",
      "Episode 70: Generating a new stochastic demand series...\n",
      "Episode 70: Total Reward = -543\n",
      "Episode 71: Generating a new stochastic demand series...\n",
      "Episode 71: Total Reward = -491\n",
      "Episode 72: Generating a new stochastic demand series...\n",
      "Episode 72: Total Reward = -360\n",
      "Episode 73: Generating a new stochastic demand series...\n",
      "Episode 73: Total Reward = -453\n",
      "Episode 74: Generating a new stochastic demand series...\n",
      "Episode 74: Total Reward = -406\n",
      "Episode 75: Generating a new stochastic demand series...\n",
      "Episode 75: Total Reward = -574\n",
      "Episode 76: Generating a new stochastic demand series...\n",
      "Episode 76: Total Reward = -509\n",
      "Episode 77: Generating a new stochastic demand series...\n",
      "Episode 77: Total Reward = -670\n",
      "Episode 78: Generating a new stochastic demand series...\n",
      "Episode 78: Total Reward = -738\n",
      "Episode 79: Generating a new stochastic demand series...\n",
      "Episode 79: Total Reward = -445\n",
      "Episode 80: Generating a new stochastic demand series...\n",
      "Episode 80: Total Reward = -499\n",
      "Episode 81: Generating a new stochastic demand series...\n",
      "Episode 81: Total Reward = -506\n",
      "Episode 82: Generating a new stochastic demand series...\n",
      "Episode 82: Total Reward = -405\n",
      "Episode 83: Generating a new stochastic demand series...\n",
      "Episode 83: Total Reward = -380\n",
      "Episode 84: Generating a new stochastic demand series...\n",
      "Episode 84: Total Reward = -466\n",
      "Episode 85: Generating a new stochastic demand series...\n",
      "Episode 85: Total Reward = -567\n",
      "Episode 86: Generating a new stochastic demand series...\n",
      "Episode 86: Total Reward = -475\n",
      "Episode 87: Generating a new stochastic demand series...\n",
      "Episode 87: Total Reward = -684\n",
      "Episode 88: Generating a new stochastic demand series...\n",
      "Episode 88: Total Reward = -381\n",
      "Episode 89: Generating a new stochastic demand series...\n",
      "Episode 89: Total Reward = -440\n",
      "Episode 90: Generating a new stochastic demand series...\n",
      "Episode 90: Total Reward = -367\n",
      "Episode 91: Generating a new stochastic demand series...\n",
      "Episode 91: Total Reward = -253\n",
      "Episode 92: Generating a new stochastic demand series...\n",
      "Episode 92: Total Reward = -615\n",
      "Episode 93: Generating a new stochastic demand series...\n",
      "Episode 93: Total Reward = -444\n",
      "Episode 94: Generating a new stochastic demand series...\n",
      "Episode 94: Total Reward = -595\n",
      "Episode 95: Generating a new stochastic demand series...\n",
      "Episode 95: Total Reward = -555\n",
      "Episode 96: Generating a new stochastic demand series...\n",
      "Episode 96: Total Reward = -439\n",
      "Episode 97: Generating a new stochastic demand series...\n",
      "Episode 97: Total Reward = -279\n",
      "Episode 98: Generating a new stochastic demand series...\n",
      "Episode 98: Total Reward = -586\n",
      "Episode 99: Generating a new stochastic demand series...\n",
      "Episode 99: Total Reward = -704\n",
      "Episode 100: Generating a new stochastic demand series...\n",
      "Episode 100: Total Reward = -449\n",
      "env_config_name = stochastic_demand, num_episodes = 100, episode_reward_mean = -459.90, episode_reward_std = 119.17\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ray\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.policy import Policy\n",
    "from config import env_configs\n",
    "from env import env_creator\n",
    "\n",
    "\n",
    "class BaseStockPolicy(Policy):\n",
    "    \"\"\"\n",
    "    Base Stock Policy orders as much to reach a desired inventory level equal to \n",
    "    production capacity (prod_capacity) for each stage.\n",
    "    \n",
    "    The order is computed as:\n",
    "    \n",
    "    order = max{ prod_capacity - (inventory + upstream_backlog + sum(deliveries)), 0 },\n",
    "       \n",
    "    \"\"\"\n",
    "    def __init__(self, observation_space, action_space, config):\n",
    "        Policy.__init__(self, observation_space, action_space, config)\n",
    "        self.env = env_creator(config['env_config'])\n",
    "        self.observation_space = self.env.agent_observation_space\n",
    "        self.action_space = self.env.agent_action_space\n",
    "\n",
    "    def compute_actions(\n",
    "        self, obs_batch, state_batches, prev_action_batch=None, prev_reward_batch=None, info_batch=None,\n",
    "        episodes=None, **kwargs):\n",
    "        # Decode each observation.        \n",
    "        decoded_obs = [self.decode_obs(obs) for obs in obs_batch]\n",
    "        # Parse observations.\n",
    "        parsed_obs = []\n",
    "        for obs in decoded_obs:\n",
    "            if isinstance(obs, dict):\n",
    "                parsed_obs.append(obs)\n",
    "            else:\n",
    "                parsed_obs.append(self.env._parse_state(obs))\n",
    "        actions = [self.get_base_stock_action(obs) for obs in parsed_obs]\n",
    "        return actions, [], {}\n",
    "\n",
    "    def decode_obs(self, obs):\n",
    "        \"\"\"\n",
    "        Decode the o observation back to its original MultiDiscrete format.\n",
    "        If the observation is already a dictionary, return it unchanged.\n",
    "        \"\"\"\n",
    "        if isinstance(obs, dict):\n",
    "            return obs\n",
    "\n",
    "        original_obs = []\n",
    "        index = 0\n",
    "        for size in self.observation_space.nvec:\n",
    "            one_hot_vector = obs[index:index + size]\n",
    "            value = np.argmax(one_hot_vector)\n",
    "            original_obs.append(value)\n",
    "            index += size\n",
    "        return np.array(original_obs)\n",
    "\n",
    "    def get_base_stock_action(self, obs: dict, safety_ratio: float = 1.5) -> int:\n",
    "        \"\"\"\n",
    "        Computíng the order based on the base-stock policy.\n",
    "        order = desired_inventory - (inventory + upstream_backlog + sum(deliveries))\n",
    "        \"\"\"\n",
    "        desired_inventory = int(1 * obs['prod_capacity'])\n",
    "        current_position = obs['inventory'] + obs['upstream_backlog'] + np.sum(obs['deliveries'])\n",
    "        action = desired_inventory - current_position\n",
    "        action = min(max(0, action), self.env.max_production)\n",
    "        return action\n",
    "\n",
    "    def learn_on_batch(self, samples):\n",
    "        return {}\n",
    "\n",
    "    def get_weights(self):\n",
    "        return {}\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        pass\n",
    "\n",
    "\n",
    "def evaluate_policy(env_config_name: str, env_config: dict, num_episodes: int = 10):\n",
    "    \"\"\"\n",
    "    Evaluating the BaseStockPolicy by running a loop over episodes.\n",
    "    For stochastic demand environments, a new demand series is generated each episode.\n",
    "    \"\"\"\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "    register_env(\"InventoryManagementEnv\", env_creator)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    env_instance = env_creator(env_config)\n",
    "    agent_observation_space = env_instance.agent_observation_space\n",
    "    agent_action_space = env_instance.agent_action_space\n",
    "\n",
    "    # Instantiate the policy.\n",
    "    policy_config = {\"env_config\": env_config}\n",
    "    base_stock_policy = BaseStockPolicy(agent_observation_space, agent_action_space, policy_config)\n",
    "    base_stock_policy.env = env_instance\n",
    "\n",
    "    episode_rewards = []\n",
    "    for ep in range(num_episodes):\n",
    "        env_instance.reset()\n",
    "        if env_config_name == \"stochastic_demand\":\n",
    "            print(f\"Episode {ep+1}: Generating a new stochastic demand series...\")\n",
    "            env_config[\"demand_fn\"].generate_new_series()\n",
    "        episode_reward = 0\n",
    "        for period in range(env_instance.num_periods):\n",
    "            state_dict = env_instance.parse_state(env_instance.state_dict)\n",
    "            obs_batch = [state_dict[f'stage_{i}'] for i in range(env_instance.num_stages)]\n",
    "            actions, _, _ = base_stock_policy.compute_actions(obs_batch, state_batches=None)\n",
    "            action_dict = {f'stage_{i}': actions[i] for i in range(env_instance.num_stages)}\n",
    "            next_states, rewards, terminations, truncations, infos = env_instance.step(action_dict)\n",
    "            episode_reward += sum(rewards.values())\n",
    "        episode_rewards.append(episode_reward)\n",
    "        print(f\"Episode {ep+1}: Total Reward = {episode_reward}\")\n",
    "        \n",
    "    episode_reward_mean = np.mean(episode_rewards)\n",
    "    episode_reward_std = np.std(episode_rewards)\n",
    "    print(f\"env_config_name = {env_config_name}, num_episodes = {num_episodes}, \"\n",
    "          f\"episode_reward_mean = {episode_reward_mean:.2f}, episode_reward_std = {episode_reward_std:.2f}\")\n",
    "    ray.shutdown()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for env_config_name, env_config in env_configs.items():\n",
    "        evaluate_policy(env_config_name, env_config, num_episodes=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb97136a-45e2-49e0-9569-0a560c917708",
   "metadata": {},
   "source": [
    "## rQ heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0afc8f87-3a40-41a7-844e-11590cbffb14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 12:05:22,499\tINFO worker.py:1816 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = -207\n",
      "Episode 2: Total Reward = -207\n",
      "Episode 3: Total Reward = -207\n",
      "Episode 4: Total Reward = -207\n",
      "Episode 5: Total Reward = -207\n",
      "Episode 6: Total Reward = -207\n",
      "Episode 7: Total Reward = -207\n",
      "Episode 8: Total Reward = -207\n",
      "Episode 9: Total Reward = -207\n",
      "Episode 10: Total Reward = -207\n",
      "Episode 11: Total Reward = -207\n",
      "Episode 12: Total Reward = -207\n",
      "Episode 13: Total Reward = -207\n",
      "Episode 14: Total Reward = -207\n",
      "Episode 15: Total Reward = -207\n",
      "Episode 16: Total Reward = -207\n",
      "Episode 17: Total Reward = -207\n",
      "Episode 18: Total Reward = -207\n",
      "Episode 19: Total Reward = -207\n",
      "Episode 20: Total Reward = -207\n",
      "Episode 21: Total Reward = -207\n",
      "Episode 22: Total Reward = -207\n",
      "Episode 23: Total Reward = -207\n",
      "Episode 24: Total Reward = -207\n",
      "Episode 25: Total Reward = -207\n",
      "Episode 26: Total Reward = -207\n",
      "Episode 27: Total Reward = -207\n",
      "Episode 28: Total Reward = -207\n",
      "Episode 29: Total Reward = -207\n",
      "Episode 30: Total Reward = -207\n",
      "Episode 31: Total Reward = -207\n",
      "Episode 32: Total Reward = -207\n",
      "Episode 33: Total Reward = -207\n",
      "Episode 34: Total Reward = -207\n",
      "Episode 35: Total Reward = -207\n",
      "Episode 36: Total Reward = -207\n",
      "Episode 37: Total Reward = -207\n",
      "Episode 38: Total Reward = -207\n",
      "Episode 39: Total Reward = -207\n",
      "Episode 40: Total Reward = -207\n",
      "Episode 41: Total Reward = -207\n",
      "Episode 42: Total Reward = -207\n",
      "Episode 43: Total Reward = -207\n",
      "Episode 44: Total Reward = -207\n",
      "Episode 45: Total Reward = -207\n",
      "Episode 46: Total Reward = -207\n",
      "Episode 47: Total Reward = -207\n",
      "Episode 48: Total Reward = -207\n",
      "Episode 49: Total Reward = -207\n",
      "Episode 50: Total Reward = -207\n",
      "Episode 51: Total Reward = -207\n",
      "Episode 52: Total Reward = -207\n",
      "Episode 53: Total Reward = -207\n",
      "Episode 54: Total Reward = -207\n",
      "Episode 55: Total Reward = -207\n",
      "Episode 56: Total Reward = -207\n",
      "Episode 57: Total Reward = -207\n",
      "Episode 58: Total Reward = -207\n",
      "Episode 59: Total Reward = -207\n",
      "Episode 60: Total Reward = -207\n",
      "Episode 61: Total Reward = -207\n",
      "Episode 62: Total Reward = -207\n",
      "Episode 63: Total Reward = -207\n",
      "Episode 64: Total Reward = -207\n",
      "Episode 65: Total Reward = -207\n",
      "Episode 66: Total Reward = -207\n",
      "Episode 67: Total Reward = -207\n",
      "Episode 68: Total Reward = -207\n",
      "Episode 69: Total Reward = -207\n",
      "Episode 70: Total Reward = -207\n",
      "Episode 71: Total Reward = -207\n",
      "Episode 72: Total Reward = -207\n",
      "Episode 73: Total Reward = -207\n",
      "Episode 74: Total Reward = -207\n",
      "Episode 75: Total Reward = -207\n",
      "Episode 76: Total Reward = -207\n",
      "Episode 77: Total Reward = -207\n",
      "Episode 78: Total Reward = -207\n",
      "Episode 79: Total Reward = -207\n",
      "Episode 80: Total Reward = -207\n",
      "Episode 81: Total Reward = -207\n",
      "Episode 82: Total Reward = -207\n",
      "Episode 83: Total Reward = -207\n",
      "Episode 84: Total Reward = -207\n",
      "Episode 85: Total Reward = -207\n",
      "Episode 86: Total Reward = -207\n",
      "Episode 87: Total Reward = -207\n",
      "Episode 88: Total Reward = -207\n",
      "Episode 89: Total Reward = -207\n",
      "Episode 90: Total Reward = -207\n",
      "Episode 91: Total Reward = -207\n",
      "Episode 92: Total Reward = -207\n",
      "Episode 93: Total Reward = -207\n",
      "Episode 94: Total Reward = -207\n",
      "Episode 95: Total Reward = -207\n",
      "Episode 96: Total Reward = -207\n",
      "Episode 97: Total Reward = -207\n",
      "Episode 98: Total Reward = -207\n",
      "Episode 99: Total Reward = -207\n",
      "Episode 100: Total Reward = -207\n",
      "env_config_name = constant_demand Average Reward over 100 episodes: -207.00episode_reward_std = 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 12:05:26,343\tINFO worker.py:1649 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = -319\n",
      "Episode 2: Total Reward = -424\n",
      "Episode 3: Total Reward = -374\n",
      "Episode 4: Total Reward = -294\n",
      "Episode 5: Total Reward = -445\n",
      "Episode 6: Total Reward = -310\n",
      "Episode 7: Total Reward = -296\n",
      "Episode 8: Total Reward = -427\n",
      "Episode 9: Total Reward = -377\n",
      "Episode 10: Total Reward = -321\n",
      "Episode 11: Total Reward = -400\n",
      "Episode 12: Total Reward = -446\n",
      "Episode 13: Total Reward = -284\n",
      "Episode 14: Total Reward = -485\n",
      "Episode 15: Total Reward = -422\n",
      "Episode 16: Total Reward = -371\n",
      "Episode 17: Total Reward = -298\n",
      "Episode 18: Total Reward = -320\n",
      "Episode 19: Total Reward = -382\n",
      "Episode 20: Total Reward = -414\n",
      "Episode 21: Total Reward = -347\n",
      "Episode 22: Total Reward = -298\n",
      "Episode 23: Total Reward = -406\n",
      "Episode 24: Total Reward = -354\n",
      "Episode 25: Total Reward = -359\n",
      "Episode 26: Total Reward = -330\n",
      "Episode 27: Total Reward = -333\n",
      "Episode 28: Total Reward = -338\n",
      "Episode 29: Total Reward = -427\n",
      "Episode 30: Total Reward = -376\n",
      "Episode 31: Total Reward = -340\n",
      "Episode 32: Total Reward = -392\n",
      "Episode 33: Total Reward = -338\n",
      "Episode 34: Total Reward = -319\n",
      "Episode 35: Total Reward = -375\n",
      "Episode 36: Total Reward = -378\n",
      "Episode 37: Total Reward = -245\n",
      "Episode 38: Total Reward = -377\n",
      "Episode 39: Total Reward = -339\n",
      "Episode 40: Total Reward = -309\n",
      "Episode 41: Total Reward = -320\n",
      "Episode 42: Total Reward = -360\n",
      "Episode 43: Total Reward = -317\n",
      "Episode 44: Total Reward = -439\n",
      "Episode 45: Total Reward = -264\n",
      "Episode 46: Total Reward = -366\n",
      "Episode 47: Total Reward = -346\n",
      "Episode 48: Total Reward = -337\n",
      "Episode 49: Total Reward = -387\n",
      "Episode 50: Total Reward = -310\n",
      "Episode 51: Total Reward = -348\n",
      "Episode 52: Total Reward = -328\n",
      "Episode 53: Total Reward = -280\n",
      "Episode 54: Total Reward = -426\n",
      "Episode 55: Total Reward = -349\n",
      "Episode 56: Total Reward = -312\n",
      "Episode 57: Total Reward = -325\n",
      "Episode 58: Total Reward = -296\n",
      "Episode 59: Total Reward = -311\n",
      "Episode 60: Total Reward = -463\n",
      "Episode 61: Total Reward = -230\n",
      "Episode 62: Total Reward = -365\n",
      "Episode 63: Total Reward = -364\n",
      "Episode 64: Total Reward = -316\n",
      "Episode 65: Total Reward = -425\n",
      "Episode 66: Total Reward = -320\n",
      "Episode 67: Total Reward = -404\n",
      "Episode 68: Total Reward = -427\n",
      "Episode 69: Total Reward = -378\n",
      "Episode 70: Total Reward = -393\n",
      "Episode 71: Total Reward = -349\n",
      "Episode 72: Total Reward = -359\n",
      "Episode 73: Total Reward = -394\n",
      "Episode 74: Total Reward = -316\n",
      "Episode 75: Total Reward = -318\n",
      "Episode 76: Total Reward = -386\n",
      "Episode 77: Total Reward = -331\n",
      "Episode 78: Total Reward = -437\n",
      "Episode 79: Total Reward = -331\n",
      "Episode 80: Total Reward = -391\n",
      "Episode 81: Total Reward = -353\n",
      "Episode 82: Total Reward = -360\n",
      "Episode 83: Total Reward = -394\n",
      "Episode 84: Total Reward = -329\n",
      "Episode 85: Total Reward = -388\n",
      "Episode 86: Total Reward = -358\n",
      "Episode 87: Total Reward = -348\n",
      "Episode 88: Total Reward = -314\n",
      "Episode 89: Total Reward = -323\n",
      "Episode 90: Total Reward = -468\n",
      "Episode 91: Total Reward = -256\n",
      "Episode 92: Total Reward = -355\n",
      "Episode 93: Total Reward = -384\n",
      "Episode 94: Total Reward = -330\n",
      "Episode 95: Total Reward = -300\n",
      "Episode 96: Total Reward = -362\n",
      "Episode 97: Total Reward = -314\n",
      "Episode 98: Total Reward = -363\n",
      "Episode 99: Total Reward = -365\n",
      "Episode 100: Total Reward = -393\n",
      "env_config_name = variable_demand Average Reward over 100 episodes: -355.64episode_reward_std = 49.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 12:05:27,388\tINFO worker.py:1649 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = -472\n",
      "Episode 2: Total Reward = -202\n",
      "Episode 3: Total Reward = -521\n",
      "Episode 4: Total Reward = -482\n",
      "Episode 5: Total Reward = -227\n",
      "Episode 6: Total Reward = -343\n",
      "Episode 7: Total Reward = -274\n",
      "Episode 8: Total Reward = -603\n",
      "Episode 9: Total Reward = -537\n",
      "Episode 10: Total Reward = -405\n",
      "Episode 11: Total Reward = -258\n",
      "Episode 12: Total Reward = -363\n",
      "Episode 13: Total Reward = -439\n",
      "Episode 14: Total Reward = -140\n",
      "Episode 15: Total Reward = -217\n",
      "Episode 16: Total Reward = -256\n",
      "Episode 17: Total Reward = -361\n",
      "Episode 18: Total Reward = -515\n",
      "Episode 19: Total Reward = -524\n",
      "Episode 20: Total Reward = -306\n",
      "Episode 21: Total Reward = -600\n",
      "Episode 22: Total Reward = -436\n",
      "Episode 23: Total Reward = -298\n",
      "Episode 24: Total Reward = -211\n",
      "Episode 25: Total Reward = -390\n",
      "Episode 26: Total Reward = -491\n",
      "Episode 27: Total Reward = -190\n",
      "Episode 28: Total Reward = -262\n",
      "Episode 29: Total Reward = -305\n",
      "Episode 30: Total Reward = -553\n",
      "Episode 31: Total Reward = -412\n",
      "Episode 32: Total Reward = -291\n",
      "Episode 33: Total Reward = -288\n",
      "Episode 34: Total Reward = -267\n",
      "Episode 35: Total Reward = -268\n",
      "Episode 36: Total Reward = -506\n",
      "Episode 37: Total Reward = -325\n",
      "Episode 38: Total Reward = -197\n",
      "Episode 39: Total Reward = -527\n",
      "Episode 40: Total Reward = -268\n",
      "Episode 41: Total Reward = -218\n",
      "Episode 42: Total Reward = -261\n",
      "Episode 43: Total Reward = -225\n",
      "Episode 44: Total Reward = -234\n",
      "Episode 45: Total Reward = -375\n",
      "Episode 46: Total Reward = -424\n",
      "Episode 47: Total Reward = -476\n",
      "Episode 48: Total Reward = -370\n",
      "Episode 49: Total Reward = -399\n",
      "Episode 50: Total Reward = -266\n",
      "Episode 51: Total Reward = -456\n",
      "Episode 52: Total Reward = -172\n",
      "Episode 53: Total Reward = -387\n",
      "Episode 54: Total Reward = -414\n",
      "Episode 55: Total Reward = -315\n",
      "Episode 56: Total Reward = -462\n",
      "Episode 57: Total Reward = -323\n",
      "Episode 58: Total Reward = -278\n",
      "Episode 59: Total Reward = -301\n",
      "Episode 60: Total Reward = -387\n",
      "Episode 61: Total Reward = -272\n",
      "Episode 62: Total Reward = -184\n",
      "Episode 63: Total Reward = -216\n",
      "Episode 64: Total Reward = -259\n",
      "Episode 65: Total Reward = -287\n",
      "Episode 66: Total Reward = -431\n",
      "Episode 67: Total Reward = -452\n",
      "Episode 68: Total Reward = -258\n",
      "Episode 69: Total Reward = -259\n",
      "Episode 70: Total Reward = -272\n",
      "Episode 71: Total Reward = -279\n",
      "Episode 72: Total Reward = -523\n",
      "Episode 73: Total Reward = -302\n",
      "Episode 74: Total Reward = -609\n",
      "Episode 75: Total Reward = -253\n",
      "Episode 76: Total Reward = -617\n",
      "Episode 77: Total Reward = -215\n",
      "Episode 78: Total Reward = -362\n",
      "Episode 79: Total Reward = -567\n",
      "Episode 80: Total Reward = -466\n",
      "Episode 81: Total Reward = -283\n",
      "Episode 82: Total Reward = -260\n",
      "Episode 83: Total Reward = -672\n",
      "Episode 84: Total Reward = -340\n",
      "Episode 85: Total Reward = -480\n",
      "Episode 86: Total Reward = -558\n",
      "Episode 87: Total Reward = -676\n",
      "Episode 88: Total Reward = -311\n",
      "Episode 89: Total Reward = -351\n",
      "Episode 90: Total Reward = -309\n",
      "Episode 91: Total Reward = -207\n",
      "Episode 92: Total Reward = -405\n",
      "Episode 93: Total Reward = -326\n",
      "Episode 94: Total Reward = -500\n",
      "Episode 95: Total Reward = -640\n",
      "Episode 96: Total Reward = -448\n",
      "Episode 97: Total Reward = -473\n",
      "Episode 98: Total Reward = -505\n",
      "Episode 99: Total Reward = -341\n",
      "Episode 100: Total Reward = -307\n",
      "env_config_name = larger_demand Average Reward over 100 episodes: -367.48episode_reward_std = 127.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 12:05:28,458\tINFO worker.py:1649 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = -311\n",
      "Episode 2: Total Reward = -302\n",
      "Episode 3: Total Reward = -312\n",
      "Episode 4: Total Reward = -369\n",
      "Episode 5: Total Reward = -359\n",
      "Episode 6: Total Reward = -276\n",
      "Episode 7: Total Reward = -343\n",
      "Episode 8: Total Reward = -294\n",
      "Episode 9: Total Reward = -186\n",
      "Episode 10: Total Reward = -337\n",
      "Episode 11: Total Reward = -282\n",
      "Episode 12: Total Reward = -334\n",
      "Episode 13: Total Reward = -288\n",
      "Episode 14: Total Reward = -285\n",
      "Episode 15: Total Reward = -287\n",
      "Episode 16: Total Reward = -281\n",
      "Episode 17: Total Reward = -226\n",
      "Episode 18: Total Reward = -311\n",
      "Episode 19: Total Reward = -342\n",
      "Episode 20: Total Reward = -352\n",
      "Episode 21: Total Reward = -290\n",
      "Episode 22: Total Reward = -281\n",
      "Episode 23: Total Reward = -332\n",
      "Episode 24: Total Reward = -312\n",
      "Episode 25: Total Reward = -273\n",
      "Episode 26: Total Reward = -274\n",
      "Episode 27: Total Reward = -317\n",
      "Episode 28: Total Reward = -270\n",
      "Episode 29: Total Reward = -267\n",
      "Episode 30: Total Reward = -222\n",
      "Episode 31: Total Reward = -330\n",
      "Episode 32: Total Reward = -252\n",
      "Episode 33: Total Reward = -320\n",
      "Episode 34: Total Reward = -299\n",
      "Episode 35: Total Reward = -328\n",
      "Episode 36: Total Reward = -316\n",
      "Episode 37: Total Reward = -243\n",
      "Episode 38: Total Reward = -335\n",
      "Episode 39: Total Reward = -341\n",
      "Episode 40: Total Reward = -216\n",
      "Episode 41: Total Reward = -237\n",
      "Episode 42: Total Reward = -325\n",
      "Episode 43: Total Reward = -307\n",
      "Episode 44: Total Reward = -348\n",
      "Episode 45: Total Reward = -352\n",
      "Episode 46: Total Reward = -313\n",
      "Episode 47: Total Reward = -214\n",
      "Episode 48: Total Reward = -295\n",
      "Episode 49: Total Reward = -302\n",
      "Episode 50: Total Reward = -378\n",
      "Episode 51: Total Reward = -326\n",
      "Episode 52: Total Reward = -291\n",
      "Episode 53: Total Reward = -300\n",
      "Episode 54: Total Reward = -277\n",
      "Episode 55: Total Reward = -272\n",
      "Episode 56: Total Reward = -204\n",
      "Episode 57: Total Reward = -262\n",
      "Episode 58: Total Reward = -225\n",
      "Episode 59: Total Reward = -230\n",
      "Episode 60: Total Reward = -327\n",
      "Episode 61: Total Reward = -294\n",
      "Episode 62: Total Reward = -346\n",
      "Episode 63: Total Reward = -258\n",
      "Episode 64: Total Reward = -350\n",
      "Episode 65: Total Reward = -284\n",
      "Episode 66: Total Reward = -284\n",
      "Episode 67: Total Reward = -310\n",
      "Episode 68: Total Reward = -289\n",
      "Episode 69: Total Reward = -258\n",
      "Episode 70: Total Reward = -271\n",
      "Episode 71: Total Reward = -308\n",
      "Episode 72: Total Reward = -280\n",
      "Episode 73: Total Reward = -317\n",
      "Episode 74: Total Reward = -279\n",
      "Episode 75: Total Reward = -307\n",
      "Episode 76: Total Reward = -340\n",
      "Episode 77: Total Reward = -253\n",
      "Episode 78: Total Reward = -327\n",
      "Episode 79: Total Reward = -274\n",
      "Episode 80: Total Reward = -274\n",
      "Episode 81: Total Reward = -195\n",
      "Episode 82: Total Reward = -329\n",
      "Episode 83: Total Reward = -299\n",
      "Episode 84: Total Reward = -323\n",
      "Episode 85: Total Reward = -250\n",
      "Episode 86: Total Reward = -333\n",
      "Episode 87: Total Reward = -306\n",
      "Episode 88: Total Reward = -303\n",
      "Episode 89: Total Reward = -339\n",
      "Episode 90: Total Reward = -359\n",
      "Episode 91: Total Reward = -272\n",
      "Episode 92: Total Reward = -272\n",
      "Episode 93: Total Reward = -306\n",
      "Episode 94: Total Reward = -260\n",
      "Episode 95: Total Reward = -304\n",
      "Episode 96: Total Reward = -363\n",
      "Episode 97: Total Reward = -299\n",
      "Episode 98: Total Reward = -312\n",
      "Episode 99: Total Reward = -354\n",
      "Episode 100: Total Reward = -265\n",
      "env_config_name = seasonal_demand Average Reward over 100 episodes: -296.26episode_reward_std = 40.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 12:05:29,454\tINFO worker.py:1649 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = -27\n",
      "Episode 2: Total Reward = -63\n",
      "Episode 3: Total Reward = -74\n",
      "Episode 4: Total Reward = -81\n",
      "Episode 5: Total Reward = -234\n",
      "Episode 6: Total Reward = -262\n",
      "Episode 7: Total Reward = -176\n",
      "Episode 8: Total Reward = -122\n",
      "Episode 9: Total Reward = -72\n",
      "Episode 10: Total Reward = -37\n",
      "Episode 11: Total Reward = -176\n",
      "Episode 12: Total Reward = -145\n",
      "Episode 13: Total Reward = 6\n",
      "Episode 14: Total Reward = -145\n",
      "Episode 15: Total Reward = -54\n",
      "Episode 16: Total Reward = -310\n",
      "Episode 17: Total Reward = -122\n",
      "Episode 18: Total Reward = -143\n",
      "Episode 19: Total Reward = -84\n",
      "Episode 20: Total Reward = -193\n",
      "Episode 21: Total Reward = -202\n",
      "Episode 22: Total Reward = -161\n",
      "Episode 23: Total Reward = -129\n",
      "Episode 24: Total Reward = -159\n",
      "Episode 25: Total Reward = -70\n",
      "Episode 26: Total Reward = -133\n",
      "Episode 27: Total Reward = -187\n",
      "Episode 28: Total Reward = -148\n",
      "Episode 29: Total Reward = -151\n",
      "Episode 30: Total Reward = -173\n",
      "Episode 31: Total Reward = -51\n",
      "Episode 32: Total Reward = -136\n",
      "Episode 33: Total Reward = -249\n",
      "Episode 34: Total Reward = -66\n",
      "Episode 35: Total Reward = -210\n",
      "Episode 36: Total Reward = -99\n",
      "Episode 37: Total Reward = -88\n",
      "Episode 38: Total Reward = -134\n",
      "Episode 39: Total Reward = -202\n",
      "Episode 40: Total Reward = -258\n",
      "Episode 41: Total Reward = -65\n",
      "Episode 42: Total Reward = -89\n",
      "Episode 43: Total Reward = -242\n",
      "Episode 44: Total Reward = -64\n",
      "Episode 45: Total Reward = -190\n",
      "Episode 46: Total Reward = -169\n",
      "Episode 47: Total Reward = -99\n",
      "Episode 48: Total Reward = -180\n",
      "Episode 49: Total Reward = -198\n",
      "Episode 50: Total Reward = -146\n",
      "Episode 51: Total Reward = -296\n",
      "Episode 52: Total Reward = -53\n",
      "Episode 53: Total Reward = -155\n",
      "Episode 54: Total Reward = -118\n",
      "Episode 55: Total Reward = -88\n",
      "Episode 56: Total Reward = -201\n",
      "Episode 57: Total Reward = -203\n",
      "Episode 58: Total Reward = -131\n",
      "Episode 59: Total Reward = -208\n",
      "Episode 60: Total Reward = -54\n",
      "Episode 61: Total Reward = -202\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 133\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_config_name, env_config \u001b[38;5;129;01min\u001b[39;00m env_configs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 133\u001b[0m         evaluate_rq_policy(env_config_name, env_config, num_episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 117\u001b[0m, in \u001b[0;36mevaluate_rq_policy\u001b[1;34m(env_config_name, env_config, num_episodes)\u001b[0m\n\u001b[0;32m    115\u001b[0m obs_batch \u001b[38;5;241m=\u001b[39m [state_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstage_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(im_env\u001b[38;5;241m.\u001b[39mnum_stages)]\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Compute actions using the RQ_Policy.\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m actions, _, _ \u001b[38;5;241m=\u001b[39m rq_policy\u001b[38;5;241m.\u001b[39mcompute_actions(obs_batch)\n\u001b[0;32m    118\u001b[0m action_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstage_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m: actions[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(im_env\u001b[38;5;241m.\u001b[39mnum_stages)}\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# Take a step in the environment.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 25\u001b[0m, in \u001b[0;36mRQ_Policy.compute_actions\u001b[1;34m(self, obs_batch, state_batches, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# If the observation is already a dict, skip _parse_state.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m parsed_obs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     22\u001b[0m     obs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39m_parse_state(obs)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obs \u001b[38;5;129;01min\u001b[39;00m decoded_obs\n\u001b[0;32m     24\u001b[0m ]\n\u001b[1;32m---> 25\u001b[0m actions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_rq_action(obs) \u001b[38;5;28;01mfor\u001b[39;00m obs \u001b[38;5;129;01min\u001b[39;00m parsed_obs]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m actions, [], {}\n",
      "Cell \u001b[1;32mIn[2], line 25\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# If the observation is already a dict, skip _parse_state.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m parsed_obs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     22\u001b[0m     obs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39m_parse_state(obs)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obs \u001b[38;5;129;01min\u001b[39;00m decoded_obs\n\u001b[0;32m     24\u001b[0m ]\n\u001b[1;32m---> 25\u001b[0m actions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_rq_action(obs) \u001b[38;5;28;01mfor\u001b[39;00m obs \u001b[38;5;129;01min\u001b[39;00m parsed_obs]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m actions, [], {}\n",
      "Cell \u001b[1;32mIn[2], line 57\u001b[0m, in \u001b[0;36mRQ_Policy.get_rq_action\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Computing demand statistics.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m mean_demand \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(obs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msales\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 57\u001b[0m demand_std \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(obs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msales\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     58\u001b[0m lead_time \u001b[38;5;241m=\u001b[39m obs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlead_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Computing safety stock and reorder point.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3645\u001b[0m, in \u001b[0;36mstd\u001b[1;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[0;32m   3642\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3643\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m std(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, ddof\u001b[38;5;241m=\u001b[39mddof, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3645\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _methods\u001b[38;5;241m.\u001b[39m_std(a, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, ddof\u001b[38;5;241m=\u001b[39mddof,\n\u001b[0;32m   3646\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\numpy\\core\\_methods.py:206\u001b[0m, in \u001b[0;36m_std\u001b[1;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_std\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ddof\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m    205\u001b[0m          where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 206\u001b[0m     ret \u001b[38;5;241m=\u001b[39m _var(a, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, ddof\u001b[38;5;241m=\u001b[39mddof,\n\u001b[0;32m    207\u001b[0m                keepdims\u001b[38;5;241m=\u001b[39mkeepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    210\u001b[0m         ret \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39msqrt(ret, out\u001b[38;5;241m=\u001b[39mret)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\Lib\\site-packages\\numpy\\core\\_methods.py:173\u001b[0m, in \u001b[0;36m_var\u001b[1;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[0;32m    168\u001b[0m     arrmean \u001b[38;5;241m=\u001b[39m arrmean \u001b[38;5;241m/\u001b[39m rcount\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# Compute sum of squared deviations from mean\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# Note that x may not be inexact and that we need it to be an array,\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# not a scalar.\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m x \u001b[38;5;241m=\u001b[39m asanyarray(arr \u001b[38;5;241m-\u001b[39m arrmean)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, (nt\u001b[38;5;241m.\u001b[39mfloating, nt\u001b[38;5;241m.\u001b[39minteger)):\n\u001b[0;32m    176\u001b[0m     x \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mmultiply(x, x, out\u001b[38;5;241m=\u001b[39mx)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class RQ_Policy:\n",
    "    \"\"\"\n",
    "    (R, Q) Policy for a single-item inventory control problem.\n",
    "    \n",
    "    At each review period (every `review_interval` time steps), if the pipeline inventory is below \n",
    "    the reorder point (R), the policy orders a fixed quantity (Q). Otherwise, no order is placed.\n",
    "    \"\"\"\n",
    "    def __init__(self, observation_space, action_space, config):\n",
    "        # This policy is used for simulation; no learning is performed.\n",
    "        self.env = env_creator(config['env_config'])\n",
    "        self.observation_space = self.env.agent_observation_space\n",
    "        self.action_space = self.env.agent_action_space\n",
    "        self.review_interval = config.get(\"review_interval\", 1)\n",
    "        self.order_quantity = config.get(\"order_quantity\", 5)\n",
    "        self.safety_ratio = config.get(\"safety_ratio\", 1.5)\n",
    "\n",
    "    def compute_actions(self, obs_batch, state_batches=None, **kwargs):\n",
    "        # Decode observations: if already a dictionary, return as-is.\n",
    "        decoded_obs = [self.decode_obs(obs) for obs in obs_batch]\n",
    "        # If the observation is already a dict, skip _parse_state.\n",
    "        parsed_obs = [\n",
    "            obs if isinstance(obs, dict) else self.env._parse_state(obs)\n",
    "            for obs in decoded_obs\n",
    "        ]\n",
    "        actions = [self.get_rq_action(obs) for obs in parsed_obs]\n",
    "        return actions, [], {}\n",
    "\n",
    "    def decode_obs(self, obs):\n",
    "        \"\"\"\n",
    "        Decoding an observation back into its original MultiDiscrete format.\n",
    "        If the observation is already a dictionary, assume it is already decoded.\n",
    "        \"\"\"\n",
    "        if isinstance(obs, dict):\n",
    "            return obs\n",
    "        original_obs = []\n",
    "        index = 0\n",
    "        for size in self.observation_space.nvec:\n",
    "            one_hot_vector = obs[index:index + size]\n",
    "            value = np.argmax(one_hot_vector)\n",
    "            original_obs.append(value)\n",
    "            index += size\n",
    "        return np.array(original_obs)\n",
    "\n",
    "    def get_rq_action(self, obs: dict) -> int:\n",
    "        \"\"\"\n",
    "        Compute the (R, Q) action.\n",
    "        If the current period is not a review period, no order is placed.\n",
    "        Otherwise, the policy computes the reorder point (R) based on historical sales and lead time.\n",
    "        If the pipeline inventory is below R, it orders a fixed quantity (Q).\n",
    "        \"\"\"\n",
    "        current_period = obs.get(\"period\", 0)\n",
    "        if self.review_interval > 1 and (current_period % self.review_interval != 0):\n",
    "            return 0\n",
    "\n",
    "        # Computing demand statistics.\n",
    "        mean_demand = np.mean(obs['sales'])\n",
    "        demand_std = np.std(obs['sales'])\n",
    "        lead_time = obs['lead_time']\n",
    "\n",
    "        # Computing safety stock and reorder point.\n",
    "        safety_stock = self.safety_ratio * demand_std * np.sqrt(lead_time)\n",
    "        reorder_point = mean_demand * lead_time + safety_stock\n",
    "\n",
    "        # Computing pipeline inventory.\n",
    "        pipeline_inventory = obs['inventory'] + obs['upstream_backlog'] + np.sum(obs['deliveries'])\n",
    "        order = self.order_quantity if pipeline_inventory < reorder_point else 0\n",
    "\n",
    "        # Ensuring order quantity is within valid bounds.\n",
    "        order = min(max(0, int(order)), self.env.max_production)\n",
    "        return order\n",
    "\n",
    "    def learn_on_batch(self, samples):\n",
    "        return {}\n",
    "\n",
    "    def get_weights(self):\n",
    "        return {}\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        pass\n",
    "\n",
    "\n",
    "def evaluate_rq_policy(env_config_name: str, env_config: dict, num_episodes: int = 10):\n",
    "    \"\"\"\n",
    "    Evaluate the RQ_Policy in the inventory management environment.\n",
    "    \n",
    "    For each episode, the environment is reset, and, if stochastic demand is configured,\n",
    "    a new demand series is generated once per episode.\n",
    "    \"\"\"\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "    register_env(\"InventoryManagementEnv\", env_creator)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # Create one environment instance to extract observation/action spaces.\n",
    "    im_env = env_creator(env_config)\n",
    "    agent_observation_space = im_env.agent_observation_space\n",
    "    agent_action_space = im_env.agent_action_space\n",
    "\n",
    "    # Instantiate the RQ_Policy. Override its internal env with our simulation instance.\n",
    "    policy_config = {\"env_config\": env_config}\n",
    "    rq_policy = RQ_Policy(agent_observation_space, agent_action_space, policy_config)\n",
    "    rq_policy.env = im_env\n",
    "\n",
    "    episode_rewards = []\n",
    "    for ep in range(num_episodes):\n",
    "        # Reset environment for a new episode.\n",
    "        im_env.reset()\n",
    "        if env_config_name == \"stochastic_demand\":\n",
    "            print(f\"Episode {ep + 1}: Generating a new stochastic demand series...\")\n",
    "            env_config[\"demand_fn\"].generate_new_series()\n",
    "\n",
    "        episode_reward = 0\n",
    "        for period in range(im_env.num_periods):\n",
    "            # Getring current state of the environment.\n",
    "            state_dict = im_env.parse_state(im_env.state_dict)\n",
    "            obs_batch = [state_dict[f'stage_{i}'] for i in range(im_env.num_stages)]\n",
    "            # Compute actions using the RQ_Policy.\n",
    "            actions, _, _ = rq_policy.compute_actions(obs_batch)\n",
    "            action_dict = {f'stage_{i}': actions[i] for i in range(im_env.num_stages)}\n",
    "            # Take a step in the environment.\n",
    "            next_states, rewards, terminations, truncations, infos = im_env.step(action_dict)\n",
    "            episode_reward += sum(rewards.values())\n",
    "        episode_rewards.append(episode_reward)\n",
    "        print(f\"Episode {ep + 1}: Total Reward = {episode_reward}\")\n",
    "\n",
    "    episode_reward_std = np.std(episode_rewards)\n",
    "    avg_reward = np.mean(episode_rewards)\n",
    "    print(f\"env_config_name = {env_config_name}\", \n",
    "        f\"Average Reward over {num_episodes} episodes: {avg_reward:.2f}\"\n",
    "          f\"episode_reward_std = {episode_reward_std:.2f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for env_config_name, env_config in env_configs.items():\n",
    "        evaluate_rq_policy(env_config_name, env_config, num_episodes=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gpu_env)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
